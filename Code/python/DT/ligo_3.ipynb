{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547de692-9159-4a80-ad51-5dee6b41be29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#总体思路：\n",
    "#高斯噪声对比时域or时频域\n",
    "#真实噪声对比更合适的数据方式，进行参数推断（H，Ωm定死）(透镜模型以及波形的泛化性)\n",
    "#真实噪声利用folw尝试信号类型判断\n",
    "#真实噪声尝试宇宙学参数推断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28acf06-bd41-49fd-af20-c179063592a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42142503-60fe-418c-b243-2ea184bbad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from scipy.integrate import quad\n",
    "#函数定义\n",
    "def lcdm_distance_redshift(z, H0, Omega_m, Omega_Lambda):\n",
    "    c = 299792.458  # 光速，单位：km/s\n",
    "    # 定义被积函数\n",
    "    integrand = lambda z: 1 / np.sqrt(Omega_m * (1 + z)**3 + Omega_Lambda)\n",
    "    # 积分计算\n",
    "    result, _ = quad(integrand, 0, z)\n",
    "    # 计算距离\n",
    "    distance = c / H0 * result*(1+z)\n",
    "    return distance\n",
    "\n",
    "\n",
    "dl_all=[]\n",
    "for zz in np.linspace(0,10,5000):\n",
    "    dl_all.append(lcdm_distance_redshift(zz,70,0.3,0.7))\n",
    "    \n",
    "f_dl_z = scipy.interpolate.interp1d(dl_all, np.linspace(0,10,5000), kind='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7b886-767b-479b-af24-815fe3cbb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_all=[]\n",
    "for zz in np.linspace(0,10,5000):\n",
    "    dl_all.append(lcdm_distance_redshift(zz,70,0.3,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f8b25-d172-42c3-8223-619fa9e3b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,10,5000),dl_all)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417f8a1-5fa6-416c-acdb-8f1d93344dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1024——glitch生成\n",
    "import matplotlib.pyplot as pp\n",
    "import matplotlib.pyplot as plt\n",
    "from pycbc.waveform import get_td_waveform,get_fd_waveform\n",
    "from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "from pycbc.filter import sigma\n",
    "from pycbc import types\n",
    "from pycbc.detector import Detector\n",
    "from pycbc.filter import matched_filter\n",
    "import pycbc\n",
    "from pycbc.psd import welch\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "from pycbc import waveform\n",
    "import scipy\n",
    "import h5py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from pycbc import distributions\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from gwpy.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340ce867-ac6f-4fc2-92a7-dc92ad841a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "#函数定义\n",
    "def lcdm_distance_redshift(z, H0, Omega_m, Omega_Lambda):\n",
    "    c = 299792.458  # 光速，单位：km/s\n",
    "    # 定义被积函数\n",
    "    integrand = lambda z: 1 / np.sqrt(Omega_m * (1 + z)**3 + Omega_Lambda)\n",
    "    # 积分计算\n",
    "    result, _ = quad(integrand, 0, z)\n",
    "    # 计算距离\n",
    "    distance = c / H0 * result*(1+z)\n",
    "    return distance\n",
    "\n",
    "\n",
    "dl_all=[]\n",
    "for zz in np.linspace(0,10,5000):\n",
    "    dl_all.append(lcdm_distance_redshift(zz,70,0.3,0.7))\n",
    "    \n",
    "f_dl_z = scipy.interpolate.interp1d(dl_all, np.linspace(0,10,5000), kind='linear')\n",
    "\n",
    "import numpy as np\n",
    "#点质量透镜模型\n",
    "class Point_mass_lens_model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def F_f(self, f, M_LZ, epsilon, D_L, xi_0, D_s):\n",
    "        return np.abs(self.miu_p(self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))**0.5 - \\\n",
    "            1j * np.abs(self.miu_c(self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))**0.5 * \\\n",
    "            np.exp(2j * np.pi * f * self.dt(M_LZ, self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))\n",
    "    \n",
    "    def miu_p(self, y, beta):\n",
    "        return 0.5 + (y**2 + 2) / (2 * y * beta)\n",
    "    \n",
    "    def miu_c(self, y, beta):\n",
    "        return 0.5 - (y**2 + 2) / (2 * y * beta)\n",
    "    #G:m³/kg·s²\n",
    "    def dt(self, M_LZ, y, beta):#单位s\n",
    "        return 4 * M_LZ*(y * beta / 2 + np.log((beta + y) / (beta - y))) * scipy.constants.G / scipy.constants.c**3 *(1.989e30)\n",
    "    \n",
    "    def beta(self, y):\n",
    "        return (y**2 + 4)**0.5\n",
    "    \n",
    "    def y(self, epsilon, D_L, xi_0, D_s):\n",
    "        return epsilon * D_L / xi_0 / D_s\n",
    "\n",
    "\n",
    "def M_L_Z(M_L,z):\n",
    "    return M_L*(1+z)\n",
    "    \n",
    "def x_i_0(M_L,D_LS,D_L,D_S): #G:m³/kg·s² #m^1 kg^-1 Mc^1  Mpc^1 单位转化成MPc,,,,1.989×1030 千克,,,3.0857E+22\n",
    "    return ((4*scipy.constants.G*M_L/scipy.constants.c**2)*(D_LS*D_L/D_S) /(3.0857e22)*(1.989e30))**0.5\n",
    "\n",
    "def mc_q_to_m1_m2(mc,q):\n",
    "    m1=(mc**5*(1+q)/q**3)**(1/5)\n",
    "    m2=m1*q\n",
    "    return m1,m2\n",
    "\n",
    "\n",
    "def get_snr(data,T_obs,fs,psd):\n",
    "    #波形、1、频率、psd\n",
    "    N = T_obs*fs\n",
    "    delta_f = 1.0/T_obs\n",
    "    delta_t = 1.0/fs\n",
    "\n",
    "#     win = tukey(N,alpha=1.0/8.0)\n",
    "    idx = np.argwhere(psd==0.0)\n",
    "    psd[idx] = 1e300    \n",
    "\n",
    "    xf = np.fft.rfft(data)*delta_t\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(np.real(xf))\n",
    "    #plt.plot(np.imag(xf))\n",
    "    SNRsq = 4.0*np.sum((np.abs(xf)**2)/psd)*delta_f\n",
    "    return np.sqrt(SNRsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62eef3d-e311-4c60-a40e-67eb2fb044e3",
   "metadata": {},
   "source": [
    "# 导入O4psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb5ddd-a36f-4d8c-9008-3722d0aca906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#固定的参数\n",
    "calculator = Point_mass_lens_model()\n",
    "T_obs=10\n",
    "N_fs=4096#采样率为4096Hz\n",
    "N_s=T_obs*N_fs#对应时域为10s\n",
    "\n",
    "flen = round(N_s/2)+1\n",
    "delta_f = 1.0 / T_obs\n",
    "delta_t=1/N_fs\n",
    "f_low=30\n",
    "flow=30\n",
    "\n",
    "tsamples = int(T_obs / delta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c315b6-72d5-49a9-bc9d-436127418ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开txt文件以读取内容\n",
    "with open('/home/suntianyang/work5/ligo/aligo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdh = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdh.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdh.sample_frequencies<f_low]=0\n",
    "psdh.data=y_new\n",
    "psdh_snr = psdh.copy()\n",
    "\n",
    "pp.plot(psdh.sample_frequencies, psdh**0.5, label='O4')\n",
    "pp.yscale('log')\n",
    "pp.xscale('log') \n",
    "pp.xlim(10,2048)\n",
    "pp.legend()\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce1f28-2f18-456c-94c6-262d7c928c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开txt文件以读取内容\n",
    "with open('/home/suntianyang/work5/ligo/aligo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdl = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdl.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdl.sample_frequencies<f_low]=0\n",
    "psdl.data=y_new\n",
    "psdl_snr = psdl.copy()\n",
    "\n",
    "\n",
    "pp.plot(psdl.sample_frequencies, psdl**0.5, label='O4')\n",
    "pp.yscale('log')\n",
    "pp.xscale('log') \n",
    "pp.xlim(10,2048)\n",
    "pp.legend()\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19bba53-a01a-449c-b995-3f95cb63b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开txt文件以读取内容\n",
    "with open('/home/suntianyang/work5/ligo/avirgo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdv = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdv.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdv.sample_frequencies<f_low]=0\n",
    "psdv.data=y_new\n",
    "psdv_snr = psdv.copy()\n",
    "\n",
    "\n",
    "pp.plot(psdv.sample_frequencies, psdv**0.5, label='O4')\n",
    "pp.yscale('log')\n",
    "pp.xscale('log') \n",
    "pp.xlim(10,2048)\n",
    "pp.legend()\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9c9af-4986-483f-ac77-bf67a93f6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开txt文件以读取内容\n",
    "with open('/home/suntianyang/work5/ligo/k1_o4_high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdk = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdk.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdk.sample_frequencies<f_low]=0\n",
    "psdk.data=y_new\n",
    "psdk_snr = psdk.copy()\n",
    "\n",
    "\n",
    "pp.plot(psdk.sample_frequencies, psdk**0.5, label='O4')\n",
    "pp.yscale('log')\n",
    "pp.xscale('log') \n",
    "pp.xlim(10,2048)\n",
    "pp.legend()\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb269784-138a-456f-9536-06bda541031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdl.sample_frequencies.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea64a58-d508-4e67-b408-c8d1d70c298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.plot(psdl.sample_frequencies, psdl**0.5, label='ligo')\n",
    "pp.plot(psdh.sample_frequencies, psdh**0.5, label='ligo')\n",
    "pp.plot(psdv.sample_frequencies, psdv**0.5, label='V1')\n",
    "pp.plot(psdk.sample_frequencies, psdk**0.5, label='K1')\n",
    "pp.yscale('log')\n",
    "pp.xscale('log') \n",
    "pp.xlim(20,2048)\n",
    "pp.legend()\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a5b2e-2237-4f36-9fd3-e740eb6c684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#固定的参数\n",
    "calculator = Point_mass_lens_model()\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "\n",
    "def get_wave_plus_gaosnoise_tf(sa):\n",
    "    hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "    while True:\n",
    "        epsilon=random.uniform(1e-6,0.5)*1e-6#MPc\n",
    "        dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(10,6000))#MPc\n",
    "        dl_samples=dl_distribution.rvs(size=1)\n",
    "        D_L=dl_samples[0][0]\n",
    "        dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(D_L,6000+D_L))#MPc\n",
    "        dl_samples=dl_distribution.rvs(size=1)\n",
    "        D_LS=dl_samples[0][0]-D_L#MPc\n",
    "        \n",
    "        M_L=random.uniform(1e3,1e5)#M\n",
    "        D_S=D_LS+D_L#MPc\n",
    "        z=f_dl_z(D_L)#MPc_z\n",
    "        z_s=f_dl_z(D_S)#MPc_z\n",
    "        M_LZ=M_L_Z(M_L,z)#M\n",
    "        xi_0=x_i_0(M_L,D_LS,D_L,D_S)\n",
    "\n",
    "        #print(calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "        #print(calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "        #print(calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "\n",
    "        dtt=calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        miu_pp=calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        miu_cc=calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        if dtt<2.25e-3 or dtt>3.52 or miu_pp<1.7 or miu_pp>10.51 or miu_cc<-9.51 or miu_cc>-0.17:\n",
    "            continue\n",
    "        \n",
    "        #print(dtt,miu_pp,miu_cc)\n",
    "        result = types.FrequencySeries(calculator.F_f(f=hp_flens.sample_frequencies.data, M_LZ=M_LZ, epsilon=epsilon, D_L=D_L, xi_0=xi_0, D_s=D_S),delta_f=N_fs/N_s)\n",
    "        \n",
    "        tc=random.uniform(7,8)\n",
    "        mc_distribution=distributions.MchirpfromUniformMass1Mass2(mc=(5,80))\n",
    "        q_distribution=distributions.QfromUniformMass1Mass2(q=(0.5,2.0))#0.5-1\n",
    "        mc_samples = mc_distribution.rvs(size=1)\n",
    "        q_samples = q_distribution.rvs(size=1)\n",
    "        mc=mc_samples[0][0]\n",
    "        q=q_samples[0][0]\n",
    "        m1,m2=mc_q_to_m1_m2(mc,q)\n",
    "        distance=D_S\n",
    "        \n",
    "        sky_distribution = distributions.sky_location.UniformSky()\n",
    "        sky_samples=sky_distribution.rvs(size=1)\n",
    "        dec = sky_samples[0][0]#纬度\n",
    "        ra = sky_samples[0][1]#经度\n",
    "        \n",
    "        psi = random.uniform(0,np.pi*2)#偏振角ψ\n",
    "        inc=np.arccos(-1.0 + 2.0*np.random.rand())#倾角\n",
    "        coa_phase=random.uniform(0,np.pi*2)#合并相位\n",
    "        #IMRPhenomPv2，SEOBNRv4_opt,IMRPhenomTPHM\n",
    "        try:\n",
    "            hp, hc = get_td_waveform(approximant='IMRPhenomTPHM',\n",
    "                                     mass1=m1*(1+z_s),#红移质量1\n",
    "                                     mass2=m2*(1+z_s),#红移质量2\n",
    "                                     distance=distance,#距离，MPC\n",
    "                                     coa_phase=coa_phase,#合并相位\n",
    "                                     inclination=inc,#轨道和视线的夹角\n",
    "                                     spin1x=0,\n",
    "                                     spin1y=0,\n",
    "                                     spin1z=0,#自旋1\n",
    "                                     spin2x=0,\n",
    "                                     spin2y=0,\n",
    "                                     spin2z=0,#自旋2\n",
    "                                     eccentricity=0,#轨道偏心率\n",
    "                                     lambda1=0,#潮汐相，中子星有\n",
    "                                     lambda2=0,\n",
    "                                     delta_t=1.0/N_fs,\n",
    "                                     f_lower=30)\n",
    "        except:\n",
    "            continue\n",
    "        fp_1, fc_1 = det_1.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_2, fc_2 = det_2.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_3, fc_3 = det_3.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_4, fc_4 = det_4.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        \n",
    "        ht_1 = fp_1*hp + fc_1*hc\n",
    "        ht_2 = fp_2*hp + fc_2*hc\n",
    "        ht_3 = fp_3*hp + fc_3*hc\n",
    "        ht_4 = fp_4*hp + fc_4*hc\n",
    "        \n",
    "        \n",
    "        ht_1.resize(N_s)\n",
    "        ht_1=ht_1.cyclic_time_shift(ht_1.start_time+tc)\n",
    "        ht_1.start_time=0\n",
    "        ht_2.resize(N_s)\n",
    "        ht_2=ht_2.cyclic_time_shift(ht_2.start_time+tc)\n",
    "        ht_2.start_time=0\n",
    "        ht_3.resize(N_s)\n",
    "        ht_3=ht_3.cyclic_time_shift(ht_3.start_time+tc)\n",
    "        ht_3.start_time=0\n",
    "        ht_4.resize(N_s)\n",
    "        ht_4=ht_4.cyclic_time_shift(ht_4.start_time+tc)\n",
    "        ht_4.start_time=0\n",
    "        \n",
    "        hp_f_1=ht_1.to_frequencyseries()\n",
    "        hp_flens_1=hp_f_1*result\n",
    "        hp_t_lens_1=hp_flens_1.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_2=ht_2.to_frequencyseries()\n",
    "        hp_flens_2=hp_f_2*result\n",
    "        hp_t_lens_2=hp_flens_2.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_3=ht_3.to_frequencyseries()\n",
    "        hp_flens_3=hp_f_3*result\n",
    "        hp_t_lens_3=hp_flens_3.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_4=ht_4.to_frequencyseries()\n",
    "        hp_flens_4=hp_f_4*result\n",
    "        hp_t_lens_4=hp_flens_4.to_timeseries()\n",
    "        \n",
    "        \n",
    "        #利用高斯 psd生成噪声：\n",
    "        noise_et1 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdl)\n",
    "        #添加非高斯噪声后要用welch方法估计psd——假设没有方法能合理的估计psd（psd中包含各种非高斯的干扰）\n",
    "        hp_t_lens_plusnoise_1=hp_t_lens_1.copy()\n",
    "        hp_t_lens_plusnoise_1.data+=noise_et1.data\n",
    "        \n",
    "        noise_et2 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdh)\n",
    "        hp_t_lens_plusnoise_2=hp_t_lens_2.copy()\n",
    "        hp_t_lens_plusnoise_2.data+=noise_et2.data\n",
    "        \n",
    "        noise_et3 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdv)\n",
    "        hp_t_lens_plusnoise_3=hp_t_lens_3.copy()\n",
    "        hp_t_lens_plusnoise_3.data+=noise_et3.data\n",
    "        \n",
    "        noise_et4 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdk)\n",
    "        hp_t_lens_plusnoise_4=hp_t_lens_4.copy()\n",
    "        hp_t_lens_plusnoise_4.data+=noise_et4.data\n",
    "        \n",
    "        snr1 = get_snr(hp_t_lens_1,T_obs,N_fs,psdl_snr.data)\n",
    "        snr2 = get_snr(hp_t_lens_2,T_obs,N_fs,psdh_snr.data)\n",
    "        snr3 = get_snr(hp_t_lens_3,T_obs,N_fs,psdv_snr.data)\n",
    "        snr4 = get_snr(hp_t_lens_4,T_obs,N_fs,psdk_snr.data)\n",
    "        snr=(snr1**2+snr2**2+snr3**2+snr4**2)**0.5\n",
    "        #print(snr)\n",
    "        \n",
    "        #print(snr)\n",
    "        if snr<16:\n",
    "            continue\n",
    "            \n",
    "        noise=TimeSeries(hp_t_lens_plusnoise_1.data)\n",
    "        noise.dt=1/N_fs\n",
    "        arr_1 = noise.q_transform(qrange=(35, 50),tres=0.01,fres=1.865)\n",
    "        \n",
    "        #print(arr_1.frequencies)\n",
    "        \n",
    "        noise=TimeSeries(hp_t_lens_plusnoise_2.data)\n",
    "        noise.dt=1/N_fs\n",
    "        arr_2 = noise.q_transform(qrange=(35, 50),tres=0.01,fres=1.865)\n",
    "        \n",
    "        noise=TimeSeries(hp_t_lens_plusnoise_3.data)\n",
    "        noise.dt=1/N_fs\n",
    "        arr_3 = noise.q_transform(qrange=(35, 50),tres=0.01,fres=1.865)\n",
    "\n",
    "        noise=TimeSeries(hp_t_lens_plusnoise_4.data)\n",
    "        noise.dt=1/N_fs\n",
    "        arr_4 = noise.q_transform(qrange=(35, 50),tres=0.01,fres=1.865)\n",
    "        \n",
    "        canshu=[epsilon,D_L,distance,M_L,mc,q,dec,ra,psi,inc,coa_phase,tc]#12个\n",
    "        return [(arr_1),(arr_2),(arr_3),(arr_4)],canshu\n",
    "        #return [np.array(arr_1.data),np.array(arr_2.data),np.array(arr_3.data),np.array(arr_4.data)],canshu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037dc5d-c4f7-423a-8ad3-e4ab9848bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_t_lens_plusnoise,canshu=get_wave_plus_gaosnoise_tf(11)\n",
    "#hp_t_lens_plusnoise[0].plot();\n",
    "#plt.xlim(23,27)\n",
    "#plt.yscale('log')\n",
    "print(hp_t_lens_plusnoise[0].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c93c9-1c90-413b-bbbc-66ee59540ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_t_lens_plusnoise[0].plot();\n",
    "hp_t_lens_plusnoise[1].plot();\n",
    "hp_t_lens_plusnoise[2].plot();\n",
    "hp_t_lens_plusnoise[3].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a7193-3da4-4d3c-9153-371f7f4931f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(30*4096)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f894f-a7bd-449e-809e-74cc51c4fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_t_lens_plusnoise.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a616a6c-e584-4955-8a2c-566ab832c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hp_t_lens_plusnoise,canshu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02517f-eb80-41b3-a91f-8433942d94a8",
   "metadata": {},
   "source": [
    "# 生成的流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495b2b7-86e8-4422-9016-57859df8ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as nn_utils\n",
    "import zuko\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lampe.data import JointLoader\n",
    "from lampe.inference import NPE, NPELoss\n",
    "from lampe.plots import nice_rc, corner, mark_point\n",
    "from lampe.utils import GDStep\n",
    "from lampe.data import H5Dataset\n",
    "from lampe.diagnostics import expected_coverage_mc\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a018c5-5c57-45b6-8acf-9d4881ac9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#抽样器1500训练\n",
    "LABELS = [r'$epsilon$',r'$D_L$',r'$distance$',r'$M_L$',r'$Mc$',r'$q$',r'$dec$',r'$ra$',r'$psi$',r'$inc$',r'$coa_phase$',r'$tc$']\n",
    "\n",
    "LOWER = torch.tensor([1e-12  , 10. ,20. ,1e3 ,5.  ,0.5 ,-0.5*np.pi   ,0       ,0       ,0       ,0       ,7])\n",
    "UPPER = torch.tensor([0.5e-6 , 6e3 ,1.2e4 ,1e5 ,80. ,2.  ,0.5*np.pi    ,2*np.pi ,2*np.pi ,2*np.pi ,2*np.pi ,8])\n",
    "        \n",
    "#参数归一化与逆运算\n",
    "def preprocess(theta: torch.Tensor) -> torch.Tensor:\n",
    "    return 2 * (theta - LOWER) / (UPPER - LOWER) - 1\n",
    "\n",
    "def postprocess(theta: torch.Tensor) -> torch.Tensor:\n",
    "    return (theta + 1) / 2 * (UPPER - LOWER) + LOWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549103b-d908-404b-8227-724b1dc4d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3973f07-c358-44fa-8760-a06b4944c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = psutil.Process()\n",
    "memory_info = process.memory_info()\n",
    "memory_usage = memory_info.rss / 1024/1024/1024  # 转换为KB\n",
    "print(f\"当前程序占用的内存：{memory_usage} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7422b-0213-4faf-af20-7f5b649db56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = NPE(3, 2, transforms=3, hidden_features=[64] * 3)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2dbaeb-96c8-46c6-96e0-e35192992058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63fc28-3459-4d2f-b55a-5b1146879093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#非采样器的\n",
    "torch.backends.cudnn.deterministic = True #禁用 cuDNN 的随机性，从而保证每次运行的结果都是相同的。\n",
    "\n",
    "aaaaa=[]\n",
    "\n",
    "import gc\n",
    "\n",
    "#  \"act<class 'torch.nn.modules.activation.ReLU'>学习率0.0003,正则化0.001,休眠率0.2,参数数目1024,参数层数7,流层9,中间层256,最佳损失-5.820067882537842,训练周期28\",\n",
    "#\"act<class 'torch.nn.modules.activation.ReLU'>学习率0.0003,正则化0,休眠率0.2,参数数目1024,参数层数7,流层9,中间层512,最佳损失-3.325531482696533,训练周期35\",\n",
    "for act in [nn.ReLU]:\n",
    "  for f in [0.0002]:\n",
    "    for weight_decay in [0]:\n",
    "       for liu in [zuko.flows.NSF]:\n",
    "        for transfomr in [7]:#,7\n",
    "         for num in [4096]:\n",
    "          for trans in [9]:\n",
    "           for beishu in [2048]:\n",
    "            \n",
    "            now= datetime.now()\n",
    "            def weight_init(m):\n",
    "                if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "                    nn.init.xavier_uniform_(m.weight.data)#kaiming_normal_///xavier_uniform_\n",
    "                    nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "            class Bottlrneck(torch.nn.Module):\n",
    "                def __init__(self,In_channel,Med_channel,Out_channel,downsample=False):\n",
    "                    super(Bottlrneck, self).__init__()\n",
    "                    self.stride = 1\n",
    "                    if downsample == True:\n",
    "                        self.stride = 2\n",
    "                    #在这里添加BatchNorm1d和Dropout是最合适的\n",
    "                    self.layer = torch.nn.Sequential(\n",
    "                        torch.nn.Conv1d(In_channel, Med_channel, 1, self.stride),\n",
    "                        torch.nn.BatchNorm1d(Med_channel),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Conv1d(Med_channel, Med_channel, 3, padding=1),\n",
    "                        torch.nn.BatchNorm1d(Med_channel),\n",
    "                        #torch.nn.ReLU(),\n",
    "                        torch.nn.Conv1d(Med_channel, Out_channel, 1),\n",
    "                        torch.nn.BatchNorm1d(Out_channel),\n",
    "                        #torch.nn.ReLU(),\n",
    "                    )\n",
    "\n",
    "                    if In_channel != Out_channel:\n",
    "                        self.res_layer = torch.nn.Conv1d(In_channel, Out_channel,1,self.stride)\n",
    "                    else:\n",
    "                        self.res_layer = None\n",
    "\n",
    "                    self.jia_relu=torch.nn.Sequential(torch.nn.ReLU())\n",
    "\n",
    "                def forward(self,x):\n",
    "                    if self.res_layer is not None:\n",
    "                        residual = self.res_layer(x)\n",
    "                    else:\n",
    "                        residual = x\n",
    "                    return self.jia_relu(self.layer(x)+residual)\n",
    "                \n",
    "            class Bottlrneck2d(torch.nn.Module):\n",
    "                def __init__(self,In_channel,Med_channel,Out_channel,downsample=False):\n",
    "                    super(Bottlrneck2d, self).__init__()\n",
    "                    self.stride = 1\n",
    "                    if downsample == True:\n",
    "                        self.stride = 2\n",
    "\n",
    "                    self.layer = torch.nn.Sequential(\n",
    "                        #torch.nn.Dropout(Dro),#夹\n",
    "                        torch.nn.Conv2d(In_channel, Med_channel, 1, self.stride),\n",
    "                        torch.nn.BatchNorm2d(Med_channel),\n",
    "                        torch.nn.ReLU(),\n",
    "                        #torch.nn.Dropout(Dro),#夹\n",
    "                        torch.nn.Conv2d(Med_channel, Med_channel, 3, padding=1),\n",
    "                        torch.nn.BatchNorm2d(Med_channel),\n",
    "                        #torch.nn.ReLU(),\n",
    "                        #torch.nn.Dropout(Dro),#夹\n",
    "                        torch.nn.Conv2d(Med_channel, Out_channel, 1),\n",
    "                        torch.nn.BatchNorm2d(Out_channel),\n",
    "                        #torch.nn.ReLU(),\n",
    "                    )\n",
    "\n",
    "                    if In_channel != Out_channel:\n",
    "                        self.res_layer = torch.nn.Conv2d(In_channel, Out_channel,1,self.stride)\n",
    "                    else:\n",
    "                        self.res_layer = None\n",
    "\n",
    "                def forward(self,x):\n",
    "                    if self.res_layer is not None:\n",
    "                        residual = self.res_layer(x)\n",
    "                    else:\n",
    "                        residual = x\n",
    "                    return self.layer(x)+residual\n",
    "\n",
    "            class ResNet(torch.nn.Module):\n",
    "                def __init__(self,in_channels=1,classes=5):\n",
    "                    super(ResNet, self).__init__()\n",
    "                    self.classifer = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(2048,classes)#变成每类特征的信息\n",
    "                    )\n",
    "                    \n",
    "                    self.features = torch.nn.Sequential(\n",
    "                        torch.nn.Conv2d(in_channels,64,kernel_size=7,stride=2,padding=3),\n",
    "                        torch.nn.MaxPool2d(3,2,1),\n",
    "\n",
    "                        Bottlrneck2d(64, 64, 256, False),\n",
    "                        Bottlrneck2d(256, 64, 256, False),\n",
    "                        Bottlrneck2d(256, 64, 256, False),\n",
    "                        #\n",
    "                        Bottlrneck2d(256, 128, 512, True),\n",
    "                        Bottlrneck2d(512, 128, 512, False),\n",
    "                        Bottlrneck2d(512, 128, 512, False),\n",
    "                        Bottlrneck2d(512, 128, 512, False),\n",
    "                        #\n",
    "                        Bottlrneck2d(512, 256, 1024, True),\n",
    "                        Bottlrneck2d(1024, 256, 1024, False),\n",
    "                        Bottlrneck2d(1024, 256, 1024, False),\n",
    "                        Bottlrneck2d(1024, 256, 1024, False),\n",
    "                        Bottlrneck2d(1024, 256, 1024, False),\n",
    "                        Bottlrneck2d(1024, 256, 1024, False),\n",
    "                        #\n",
    "                        Bottlrneck2d(1024, 512, 2048, True),\n",
    "                        Bottlrneck2d(2048, 512, 2048, False),\n",
    "                        Bottlrneck2d(2048, 512, 2048, False),\n",
    "\n",
    "                        torch.nn.AdaptiveAvgPool2d(1)\n",
    "                    )\n",
    "                    \n",
    "\n",
    "                def forward(self,x):\n",
    "                    x = self.features(x)\n",
    "                    x = x.view(-1,2048)\n",
    "                    x = self.classifer(x)\n",
    "                    return x\n",
    "\n",
    "            class NPEWithEmbedding(nn.Module):#这个网络只要是1维的2的倍数就行\n",
    "                def __init__(self,channels=3,beishu=4,canshu=2,build=zuko.flows.NSF,hidden_features=[128] * 3,activation=nn.ELU,transforms=3):\n",
    "                    super().__init__()\n",
    "\n",
    "                    self.npe = NPE(canshu, beishu, build=build, hidden_features=hidden_features,transforms=transforms, activation=activation)#用于\n",
    "                    self.embedding = ResNet(in_channels=channels,classes=beishu)\n",
    "\n",
    "                def forward(self, theta: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "                    #print(self.embedding(x).shape)\n",
    "\n",
    "                    return self.npe(theta, self.embedding(x))\n",
    "\n",
    "                def flow(self, x: torch.Tensor):  # -> flow对应原来的采样，因为他调用的就是flow\n",
    "                    return self.npe.flow(self.embedding(x))\n",
    "\n",
    "\n",
    "            torch.manual_seed(2234)#重置参数，在循环里面可以保证可以复现\n",
    "            estimator= NPEWithEmbedding(channels=4,canshu=12,beishu=beishu,build=liu,hidden_features=[num] * transfomr,transforms=trans,activation=act).cuda()#beishu是残差网络输出尺寸（npe的输入参数）\n",
    "            estimator.apply(weight_init)\n",
    "            \n",
    "            optimizer = optim.AdamW(estimator.parameters(), lr=f,weight_decay=weight_decay)#学习率！！！！！！！！！！！\n",
    "            #在优化器选项里添加正则化,weight_decay=0.01，l2正则化\n",
    "\n",
    "            scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)#lr_scheduler.ExponentialLR(optimizer, gamma=0.99)#学习率衰减\n",
    "            #https://zhuanlan.zhihu.com/p/363338422\n",
    "\n",
    "            step = GDStep(optimizer, clip=1.0)  # gradient descent step with gradient clipping,有了他不用optimizer.step\n",
    "            loss = NPELoss(estimator)\n",
    "\n",
    "\n",
    "            list_los = []  # 用于存储第一列数据\n",
    "            list_losvail = []  # 用于存储第二列数据\n",
    "\n",
    "            \n",
    "            with tqdm(range(2000), unit='epoch') as tq:#epoch\n",
    "                best_loss = np.inf#早停\n",
    "                best_model_weights = None\n",
    "                patience=50#10个周期不降就停\n",
    "                i=0\n",
    "                i_numca=0\n",
    "                num=6000#总数\n",
    "                num_v=1200\n",
    "                datast=15#batch_size\n",
    "                nnum=num//datast\n",
    "                nnum_v=num_v//datast\n",
    "                for epoch in tq:\n",
    "                    #losses = torch.stack([\n",
    "                    #    step(loss(preprocess(theta).cuda(), x.cuda()))\n",
    "                    #    for theta, x in trainset # 这样写是遍历全部元素，实例那样是因为他是采样器\n",
    "                    #])\n",
    "\n",
    "                    pool = Pool(processes=56)\n",
    "                    results = pool.map(get_wave_plus_gaosnoise_tf, range(num))\n",
    "                    all_x = torch.tensor(np.concatenate([x for x,y in results]).reshape(nnum,datast,4,600,600),dtype=torch.float32)\n",
    "                    all_y = torch.tensor(np.concatenate([y for x,y in results]).reshape(nnum,datast,12),dtype=torch.float32)\n",
    "\n",
    "                    results = pool.map(get_wave_plus_gaosnoise_tf, range(num_v))\n",
    "                    all_x_vail = torch.tensor(np.concatenate([x for x,y in results]).reshape(nnum_v,datast,4,600,600),dtype=torch.float32)\n",
    "                    all_y_vail = torch.tensor(np.concatenate([y for x,y in results]).reshape(nnum_v,datast,12),dtype=torch.float32)\n",
    "\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "\n",
    "                    del results\n",
    "                    \n",
    "                    losses = torch.stack([\n",
    "                        step(loss(preprocess(all_y[i]).cuda(), all_x[i].cuda()))\n",
    "                        for i in range(nnum) # 这样写是遍历全部元素，实例那样是因为他是采样器\n",
    "                    ])\n",
    "                    \n",
    "                    del all_x,all_y\n",
    "                    \n",
    "                    estimator.eval()\n",
    "                    with torch.no_grad():\n",
    "                        val_losses = torch.stack([\n",
    "                            loss(preprocess(all_y_vail[i]).cuda(), all_x_vail[i].cuda())\n",
    "                            for i in range(nnum_v)\n",
    "                        ])\n",
    "                    \n",
    "                    scheduler.step()#学习率衰减\n",
    "\n",
    "                    tq.set_postfix(loss=losses.mean().item(), val_loss=val_losses.mean().item())\n",
    "\n",
    "                    del all_x_vail,all_y_vail\n",
    "                    \n",
    "                    los=losses.mean().item()#类型不对，所以换名字\n",
    "                    losval=val_losses.mean().item()#类型不对，所以换名字\n",
    "                    \n",
    "                    list_los.append(los)#话损失函数图\n",
    "                    list_losvail.append(losval)#话损失函数图\n",
    "\n",
    "                    # 储存监视\n",
    "                    data1 = list_los\n",
    "                    data2 = list_losvail\n",
    "                    last= now\n",
    "                    now = datetime.now()\n",
    "                    # 打开一个文件用于写入\n",
    "                    file = open('/home/suntianyang/work5/ligo/net/data_train_tf.txt', 'w')\n",
    "                    file.write('last_last:'+str(last) + '\\n')\n",
    "                    file.write('___last__:'+str(now) + '\\n')\n",
    "                    \n",
    "                    # 将每个元素写入文件中\n",
    "                    for item1, item2 in zip(data1, data2):\n",
    "                        file.write(str(item1) + ' ' + str(item2) + '\\n')\n",
    "                    \n",
    "                    # 关闭文件\n",
    "                    file.close()\n",
    "                    \n",
    "                    del losses,data1,data2\n",
    "                    \n",
    "                    \n",
    "                    process = psutil.Process()\n",
    "                    memory_info = process.memory_info()\n",
    "                    memory_usage = memory_info.rss / 1024/1024/1024  # 转换为KB\n",
    "                    print(f\"当前程序占用的内存：{memory_usage} GB\")\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.save(estimator.state_dict(),f'/home/suntianyang/work5/ligo/net/NPE_mid_tf_hou.pth')\n",
    "                    \n",
    "                    if losval < best_loss:\n",
    "                        best_loss = losval\n",
    "                        epochs_without_improvement = 0\n",
    "                        best_model_weights = estimator.state_dict()\n",
    "                    else:\n",
    "                        epochs_without_improvement += 1\n",
    "                    \n",
    "                    \n",
    "                    # 如果验证集上的损失连续patience个epoch没有提高，则停止训练\n",
    "                    if epochs_without_improvement == patience:\n",
    "                        estimator.load_state_dict(best_model_weights)\n",
    "                        print('Early stopping at epoch {}...'.format(epoch-patience+1))\n",
    "                        break\n",
    "\n",
    "\n",
    "            aaaaa.append('act{}学习率{},正则化{},,参数数目{},参数层数{},流层{},中间层{},最佳损失{},训练周期{}'.format(act,f,weight_decay,num,transfomr,trans,beishu,list_los[-1-10],len(list_los)-10))\n",
    "            print('act{}学习率{},正则化{},,参数数目{},参数层数{},流层{},中间层{},最佳损失{},训练周期{}'.format(act,f,weight_decay,num,transfomr,trans,beishu,list_los[-1-10],len(list_los)-10))\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994d926-7178-4b77-b51e-7dd4c95bc42a",
   "metadata": {},
   "source": [
    "# 1d网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e74ab-cafb-4f30-a41f-303c432cba04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#固定的参数\n",
    "calculator = Point_mass_lens_model()\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "\n",
    "def get_wave_plus_gaosnoise_t(sa):\n",
    "    hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "    while True:\n",
    "        epsilon=random.uniform(1e-6,0.5)*1e-6#MPc\n",
    "        dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(10,6000))#MPc\n",
    "        dl_samples=dl_distribution.rvs(size=1)\n",
    "        D_L=dl_samples[0][0]\n",
    "        dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(D_L,6000+D_L))#MPc\n",
    "        dl_samples=dl_distribution.rvs(size=1)\n",
    "        D_LS=dl_samples[0][0]-D_L#MPc\n",
    "        \n",
    "        M_L=random.uniform(1e3,1e5)#M\n",
    "        D_S=D_LS+D_L#MPc\n",
    "        z=f_dl_z(D_L)#MPc_z\n",
    "        z_s=f_dl_z(D_S)#MPc_z\n",
    "        M_LZ=M_L_Z(M_L,z)#M\n",
    "        xi_0=x_i_0(M_L,D_LS,D_L,D_S)\n",
    "\n",
    "        #print(calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "        #print(calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "        #print(calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "\n",
    "        dtt=calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        miu_pp=calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        miu_cc=calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        if dtt<2.25e-3 or dtt>3.52 or miu_pp<1.7 or miu_pp>10.51 or miu_cc<-9.51 or miu_cc>-0.17:\n",
    "            continue\n",
    "        \n",
    "        #print(dtt,miu_pp,miu_cc)\n",
    "        result = types.FrequencySeries(calculator.F_f(f=hp_flens.sample_frequencies.data, M_LZ=M_LZ, epsilon=epsilon, D_L=D_L, xi_0=xi_0, D_s=D_S),delta_f=N_fs/N_s)\n",
    "        \n",
    "        tc=random.uniform(7,8)\n",
    "        mc_distribution=distributions.MchirpfromUniformMass1Mass2(mc=(5,80))\n",
    "        q_distribution=distributions.QfromUniformMass1Mass2(q=(0.5,2.0))#0.5-1\n",
    "        mc_samples = mc_distribution.rvs(size=1)\n",
    "        q_samples = q_distribution.rvs(size=1)\n",
    "        mc=mc_samples[0][0]\n",
    "        q=q_samples[0][0]\n",
    "        m1,m2=mc_q_to_m1_m2(mc,q)\n",
    "        distance=D_S\n",
    "        \n",
    "        sky_distribution = distributions.sky_location.UniformSky()\n",
    "        sky_samples=sky_distribution.rvs(size=1)\n",
    "        dec = sky_samples[0][0]#纬度\n",
    "        ra = sky_samples[0][1]#经度\n",
    "        \n",
    "        psi = random.uniform(0,np.pi*2)#偏振角ψ\n",
    "        inc=np.arccos(-1.0 + 2.0*np.random.rand())#倾角\n",
    "        coa_phase=random.uniform(0,np.pi*2)#合并相位\n",
    "        #IMRPhenomPv2，SEOBNRv4_opt,IMRPhenomTPHM\n",
    "        try:\n",
    "            hp, hc = get_td_waveform(approximant='IMRPhenomTPHM',\n",
    "                                     mass1=m1*(1+z_s),#红移质量1\n",
    "                                     mass2=m2*(1+z_s),#红移质量2\n",
    "                                     distance=distance,#距离，MPC\n",
    "                                     coa_phase=coa_phase,#合并相位\n",
    "                                     inclination=inc,#轨道和视线的夹角\n",
    "                                     spin1x=0,\n",
    "                                     spin1y=0,\n",
    "                                     spin1z=0,#自旋1\n",
    "                                     spin2x=0,\n",
    "                                     spin2y=0,\n",
    "                                     spin2z=0,#自旋2\n",
    "                                     eccentricity=0,#轨道偏心率\n",
    "                                     lambda1=0,#潮汐相，中子星有\n",
    "                                     lambda2=0,\n",
    "                                     delta_t=1.0/N_fs,\n",
    "                                     f_lower=30)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        fp_1, fc_1 = det_1.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_2, fc_2 = det_2.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_3, fc_3 = det_3.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_4, fc_4 = det_4.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        \n",
    "        ht_1 = fp_1*hp + fc_1*hc\n",
    "        ht_2 = fp_2*hp + fc_2*hc\n",
    "        ht_3 = fp_3*hp + fc_3*hc\n",
    "        ht_4 = fp_4*hp + fc_4*hc\n",
    "        \n",
    "        \n",
    "        ht_1.resize(N_s)\n",
    "        ht_1=ht_1.cyclic_time_shift(ht_1.start_time+tc)\n",
    "        ht_1.start_time=0\n",
    "        ht_2.resize(N_s)\n",
    "        ht_2=ht_2.cyclic_time_shift(ht_2.start_time+tc)\n",
    "        ht_2.start_time=0\n",
    "        ht_3.resize(N_s)\n",
    "        ht_3=ht_3.cyclic_time_shift(ht_3.start_time+tc)\n",
    "        ht_3.start_time=0\n",
    "        ht_4.resize(N_s)\n",
    "        ht_4=ht_4.cyclic_time_shift(ht_4.start_time+tc)\n",
    "        ht_4.start_time=0\n",
    "        \n",
    "        hp_f_1=ht_1.to_frequencyseries()\n",
    "        hp_flens_1=hp_f_1*result\n",
    "        hp_t_lens_1=hp_flens_1.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_2=ht_2.to_frequencyseries()\n",
    "        hp_flens_2=hp_f_2*result\n",
    "        hp_t_lens_2=hp_flens_2.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_3=ht_3.to_frequencyseries()\n",
    "        hp_flens_3=hp_f_3*result\n",
    "        hp_t_lens_3=hp_flens_3.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_4=ht_4.to_frequencyseries()\n",
    "        hp_flens_4=hp_f_4*result\n",
    "        hp_t_lens_4=hp_flens_4.to_timeseries()\n",
    "        \n",
    "        \n",
    "        #利用高斯 psd生成噪声：\n",
    "        noise_et1 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdl)\n",
    "        #添加非高斯噪声后要用welch方法估计psd——假设没有方法能合理的估计psd（psd中包含各种非高斯的干扰）\n",
    "        hp_t_lens_plusnoise_1=hp_t_lens_1.copy()\n",
    "        hp_t_lens_plusnoise_1.data+=noise_et1.data\n",
    "        \n",
    "        noise_et2 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdh)\n",
    "        hp_t_lens_plusnoise_2=hp_t_lens_2.copy()\n",
    "        hp_t_lens_plusnoise_2.data+=noise_et2.data\n",
    "        \n",
    "        noise_et3 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdv)\n",
    "        hp_t_lens_plusnoise_3=hp_t_lens_3.copy()\n",
    "        hp_t_lens_plusnoise_3.data+=noise_et3.data\n",
    "        \n",
    "        noise_et4 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdk)\n",
    "        hp_t_lens_plusnoise_4=hp_t_lens_4.copy()\n",
    "        hp_t_lens_plusnoise_4.data+=noise_et4.data\n",
    "        \n",
    "        snr1 = get_snr(hp_t_lens_1,T_obs,N_fs,psdl_snr.data)\n",
    "        snr2 = get_snr(hp_t_lens_2,T_obs,N_fs,psdh_snr.data)\n",
    "        snr3 = get_snr(hp_t_lens_3,T_obs,N_fs,psdv_snr.data)\n",
    "        snr4 = get_snr(hp_t_lens_4,T_obs,N_fs,psdk_snr.data)\n",
    "        snr=(snr1**2+snr2**2+snr3**2+snr4**2)**0.5\n",
    "        #print(snr)\n",
    "        \n",
    "        #print(snr)\n",
    "        if snr<16:\n",
    "            continue\n",
    "            \n",
    "        L11data = (hp_t_lens_plusnoise_1.to_frequencyseries() / psdl_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        H11data = (hp_t_lens_plusnoise_2.to_frequencyseries() / psdh_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        V11data = (hp_t_lens_plusnoise_3.to_frequencyseries() / psdv_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        K11data = (hp_t_lens_plusnoise_4.to_frequencyseries() / psdk_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "\n",
    "        canshu=[epsilon,D_L,distance,M_L,mc,q,dec,ra,psi,inc,coa_phase,tc]#12个\n",
    "        \n",
    "        return [L11data.data,H11data.data,V11data.data,K11data.data],canshu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f1212-ec5a-49f1-ae9c-d4fe4bb0f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adad,g=get_wave_plus_gaosnoise_t(11)\n",
    "plt.plot(adad[0])\n",
    "#plt.xlim(7*4096,8*4096)\n",
    "#plt.plot(adad[1])\n",
    "#plt.plot(adad[2])\n",
    "#plt.plot(adad[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d6f7b-bf51-4acc-ae09-ad79331548e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#固定的参数\n",
    "calculator = Point_mass_lens_model()\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "\n",
    "def get_wave_plus_gaosnoise_t_lens(sa):\n",
    "    hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "    while True:\n",
    "        epsilon=random.uniform(1e-6,0.5)*1e-6#MPc\n",
    "        dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(10,6000))#MPc\n",
    "        dl_samples=dl_distribution.rvs(size=1)\n",
    "        D_L=dl_samples[0][0]\n",
    "        dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(D_L,6000+D_L))#MPc\n",
    "        dl_samples=dl_distribution.rvs(size=1)\n",
    "        D_LS=dl_samples[0][0]-D_L#MPc\n",
    "        \n",
    "        M_L=random.uniform(1e3,1e5)#M\n",
    "        D_S=D_LS+D_L#MPc\n",
    "        z=f_dl_z(D_L)#MPc_z\n",
    "        z_s=f_dl_z(D_S)#MPc_z\n",
    "        M_LZ=M_L_Z(M_L,z)#M\n",
    "        xi_0=x_i_0(M_L,D_LS,D_L,D_S)\n",
    "\n",
    "        #print(calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "        #print(calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "        #print(calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "\n",
    "        dtt=calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        miu_pp=calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        miu_cc=calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        yyy_uuu=calculator.y(epsilon, D_L, xi_0, D_S)\n",
    "        if dtt<2.25e-3 or dtt>3.52 or miu_pp<1.7 or miu_pp>10.51 or miu_cc<-9.51 or miu_cc>-0.17:\n",
    "            continue\n",
    "        \n",
    "        #print(dtt,miu_pp,miu_cc)\n",
    "        result = types.FrequencySeries(calculator.F_f(f=hp_flens.sample_frequencies.data, M_LZ=M_LZ, epsilon=epsilon, D_L=D_L, xi_0=xi_0, D_s=D_S),delta_f=N_fs/N_s)\n",
    "        \n",
    "        tc=random.uniform(7,8)\n",
    "        mc_distribution=distributions.MchirpfromUniformMass1Mass2(mc=(5,80))\n",
    "        q_distribution=distributions.QfromUniformMass1Mass2(q=(0.5,2.0))#0.5-1\n",
    "        mc_samples = mc_distribution.rvs(size=1)\n",
    "        q_samples = q_distribution.rvs(size=1)\n",
    "        mc=mc_samples[0][0]\n",
    "        q=q_samples[0][0]\n",
    "        m1,m2=mc_q_to_m1_m2(mc,q)\n",
    "        distance=D_S\n",
    "        \n",
    "        sky_distribution = distributions.sky_location.UniformSky()\n",
    "        sky_samples=sky_distribution.rvs(size=1)\n",
    "        dec = sky_samples[0][0]#纬度\n",
    "        ra = sky_samples[0][1]#经度\n",
    "        \n",
    "        psi = random.uniform(0,np.pi*2)#偏振角ψ\n",
    "        inc=np.arccos(-1.0 + 2.0*np.random.rand())#倾角\n",
    "        coa_phase=random.uniform(0,np.pi*2)#合并相位\n",
    "        #IMRPhenomPv2，SEOBNRv4_opt,IMRPhenomTPHM\n",
    "        try:\n",
    "            hp, hc = get_td_waveform(approximant='IMRPhenomTPHM',\n",
    "                                     mass1=m1*(1+z_s),#红移质量1\n",
    "                                     mass2=m2*(1+z_s),#红移质量2\n",
    "                                     distance=distance,#距离，MPC\n",
    "                                     coa_phase=coa_phase,#合并相位\n",
    "                                     inclination=inc,#轨道和视线的夹角\n",
    "                                     spin1x=0,\n",
    "                                     spin1y=0,\n",
    "                                     spin1z=0,#自旋1\n",
    "                                     spin2x=0,\n",
    "                                     spin2y=0,\n",
    "                                     spin2z=0,#自旋2\n",
    "                                     eccentricity=0,#轨道偏心率\n",
    "                                     lambda1=0,#潮汐相，中子星有\n",
    "                                     lambda2=0,\n",
    "                                     delta_t=1.0/N_fs,\n",
    "                                     f_lower=30)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        fp_1, fc_1 = det_1.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_2, fc_2 = det_2.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_3, fc_3 = det_3.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_4, fc_4 = det_4.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        \n",
    "        ht_1 = fp_1*hp + fc_1*hc\n",
    "        ht_2 = fp_2*hp + fc_2*hc\n",
    "        ht_3 = fp_3*hp + fc_3*hc\n",
    "        ht_4 = fp_4*hp + fc_4*hc\n",
    "        \n",
    "        \n",
    "        ht_1.resize(N_s)\n",
    "        ht_1=ht_1.cyclic_time_shift(ht_1.start_time+tc)\n",
    "        ht_1.start_time=0\n",
    "        ht_2.resize(N_s)\n",
    "        ht_2=ht_2.cyclic_time_shift(ht_2.start_time+tc)\n",
    "        ht_2.start_time=0\n",
    "        ht_3.resize(N_s)\n",
    "        ht_3=ht_3.cyclic_time_shift(ht_3.start_time+tc)\n",
    "        ht_3.start_time=0\n",
    "        ht_4.resize(N_s)\n",
    "        ht_4=ht_4.cyclic_time_shift(ht_4.start_time+tc)\n",
    "        ht_4.start_time=0\n",
    "        \n",
    "        hp_f_1=ht_1.to_frequencyseries()\n",
    "        hp_flens_1=hp_f_1*result\n",
    "        hp_t_lens_1=hp_flens_1.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_2=ht_2.to_frequencyseries()\n",
    "        hp_flens_2=hp_f_2*result\n",
    "        hp_t_lens_2=hp_flens_2.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_3=ht_3.to_frequencyseries()\n",
    "        hp_flens_3=hp_f_3*result\n",
    "        hp_t_lens_3=hp_flens_3.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_4=ht_4.to_frequencyseries()\n",
    "        hp_flens_4=hp_f_4*result\n",
    "        hp_t_lens_4=hp_flens_4.to_timeseries()\n",
    "        \n",
    "        \n",
    "        #利用高斯 psd生成噪声：\n",
    "        noise_et1 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdl)\n",
    "        #添加非高斯噪声后要用welch方法估计psd——假设没有方法能合理的估计psd（psd中包含各种非高斯的干扰）\n",
    "        hp_t_lens_plusnoise_1=hp_t_lens_1.copy()\n",
    "        hp_t_lens_plusnoise_1.data+=noise_et1.data\n",
    "        \n",
    "        noise_et2 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdh)\n",
    "        hp_t_lens_plusnoise_2=hp_t_lens_2.copy()\n",
    "        hp_t_lens_plusnoise_2.data+=noise_et2.data\n",
    "        \n",
    "        noise_et3 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdv)\n",
    "        hp_t_lens_plusnoise_3=hp_t_lens_3.copy()\n",
    "        hp_t_lens_plusnoise_3.data+=noise_et3.data\n",
    "        \n",
    "        noise_et4 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdk)\n",
    "        hp_t_lens_plusnoise_4=hp_t_lens_4.copy()\n",
    "        hp_t_lens_plusnoise_4.data+=noise_et4.data\n",
    "        \n",
    "        snr1 = get_snr(hp_t_lens_1,T_obs,N_fs,psdl_snr.data)\n",
    "        snr2 = get_snr(hp_t_lens_2,T_obs,N_fs,psdh_snr.data)\n",
    "        snr3 = get_snr(hp_t_lens_3,T_obs,N_fs,psdv_snr.data)\n",
    "        snr4 = get_snr(hp_t_lens_4,T_obs,N_fs,psdk_snr.data)\n",
    "        snr=(snr1**2+snr2**2+snr3**2+snr4**2)**0.5\n",
    "        #print(snr)\n",
    "        \n",
    "        #print(snr)\n",
    "        if snr<16 and snr<50:\n",
    "            continue\n",
    "            \n",
    "        L11data = (hp_t_lens_plusnoise_1.to_frequencyseries() / psdl_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        H11data = (hp_t_lens_plusnoise_2.to_frequencyseries() / psdh_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        V11data = (hp_t_lens_plusnoise_3.to_frequencyseries() / psdv_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        K11data = (hp_t_lens_plusnoise_4.to_frequencyseries() / psdk_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "\n",
    "        canshu=[yyy_uuu,miu_pp,miu_cc]#12个\n",
    "        \n",
    "        return [L11data.data,H11data.data,V11data.data,K11data.data],canshu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7900ef-da2e-4ff1-a92e-8e0f2b64bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "miu_pp<1.7\n",
    "miu_pp>10.51\n",
    "\n",
    "miu_cc<-9.51\n",
    "miu_cc>-0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88610f3b-3b38-4aa2-a492-1c351acfd4ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "#pool = Pool(processes=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02028fb-4101-4630-9c27-332240f76eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.iers import IERS_Auto\n",
    "iers_a = IERS_Auto.open()\n",
    "\n",
    "import warnings\n",
    "from astropy.utils.iers import IERSStaleWarning\n",
    "\n",
    "# 忽略 IERSStaleWarning\n",
    "warnings.filterwarnings('ignore', category=IERSStaleWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fdbb3-24f7-4931-8f28-284fbeb95706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "process = psutil.Process()\n",
    "memory_info = process.memory_info()\n",
    "memory_usage = memory_info.rss / 1024/1024/1024  # 转换为KB\n",
    "\n",
    "print(f\"当前程序占用的内存：{memory_usage} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5876e2-72f0-48cd-888f-0886dda3f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(processes=56)\n",
    "results = pool.map(get_wave_plus_gaosnoise_t_lens, range(5000))\n",
    "all_x = torch.tensor(np.concatenate([x for x,y in results]).reshape(5000,4,4096*10),dtype=torch.float32)\n",
    "all_y = torch.tensor(np.concatenate([y for x,y in results]).reshape(5000,3),dtype=torch.float32)\n",
    "del results\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67569f2a-8154-4831-8ba0-b6cd5beb1e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba4719-bf3f-407d-9363-f9261fc21b2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#非采样器的\n",
    "torch.backends.cudnn.deterministic = True #禁用 cuDNN 的随机性，从而保证每次运行的结果都是相同的。\n",
    "\n",
    "aaaaa=[]\n",
    "\n",
    "import gc\n",
    "\n",
    "#  \"act<class 'torch.nn.modules.activation.ReLU'>学习率0.0003,正则化0.001,休眠率0.2,参数数目1024,参数层数7,流层9,中间层256,最佳损失-5.820067882537842,训练周期28\",\n",
    "#\"act<class 'torch.nn.modules.activation.ReLU'>学习率0.0003,正则化0,休眠率0.2,参数数目1024,参数层数7,流层9,中间层512,最佳损失-3.325531482696533,训练周期35\",\n",
    "for act in [nn.ReLU]:\n",
    "  for f in [0.0001]:\n",
    "    for weight_decay in [0]:\n",
    "       for liu in [zuko.flows.NSF]:\n",
    "        for transfomr in [7]:#,7\n",
    "         for num in [4096]:\n",
    "          for trans in [9]:\n",
    "           for beishu in [2048]:\n",
    "            now= datetime.now()\n",
    "            def weight_init(m):\n",
    "                if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "                    nn.init.xavier_uniform_(m.weight.data)#kaiming_normal_///xavier_uniform_\n",
    "                    nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "            class Bottlrneck(torch.nn.Module):\n",
    "                def __init__(self,In_channel,Med_channel,Out_channel,downsample=False):\n",
    "                    super(Bottlrneck, self).__init__()\n",
    "                    self.stride = 1\n",
    "                    if downsample == True:\n",
    "                        self.stride = 2\n",
    "                    #在这里添加BatchNorm1d和Dropout是最合适的\n",
    "                    self.layer = torch.nn.Sequential(\n",
    "                        torch.nn.Conv1d(In_channel, Med_channel, 1, self.stride),\n",
    "                        torch.nn.BatchNorm1d(Med_channel),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Conv1d(Med_channel, Med_channel, 3, padding=1),\n",
    "                        torch.nn.BatchNorm1d(Med_channel),\n",
    "                        #torch.nn.ReLU(),\n",
    "                        torch.nn.Conv1d(Med_channel, Out_channel, 1),\n",
    "                        torch.nn.BatchNorm1d(Out_channel),\n",
    "                        #torch.nn.ReLU(),\n",
    "                    )\n",
    "\n",
    "                    if In_channel != Out_channel:\n",
    "                        self.res_layer = torch.nn.Conv1d(In_channel, Out_channel,1,self.stride)\n",
    "                    else:\n",
    "                        self.res_layer = None\n",
    "\n",
    "                    self.jia_relu=torch.nn.Sequential(torch.nn.ReLU())\n",
    "\n",
    "                def forward(self,x):\n",
    "                    if self.res_layer is not None:\n",
    "                        residual = self.res_layer(x)\n",
    "                    else:\n",
    "                        residual = x\n",
    "                    return self.jia_relu(self.layer(x)+residual)\n",
    "                \n",
    "                def forward(self,x):\n",
    "                    if self.res_layer is not None:\n",
    "                        residual = self.res_layer(x)\n",
    "                    else:\n",
    "                        residual = x\n",
    "                    return self.layer(x)+residual\n",
    "\n",
    "            class ResNet(torch.nn.Module):\n",
    "                def __init__(self,in_channels=1,classes=5):\n",
    "                    super(ResNet, self).__init__()\n",
    "                    self.features = torch.nn.Sequential(\n",
    "                        torch.nn.Conv1d(in_channels,64,kernel_size=7,stride=2,padding=3),##in_channels*x*x--->64*x/2*x/2\n",
    "                        torch.nn.MaxPool1d(3,2,1),#池化——64*x/4*x/4\n",
    "\n",
    "                        Bottlrneck(64,64,256,False),\n",
    "                        Bottlrneck(256,64,256,False),\n",
    "                        Bottlrneck(256,64,256,False),#256*x/4*x/4\n",
    "\n",
    "\n",
    "\n",
    "                        Bottlrneck(256,128,512, True),#True代表卷积步长为2————256*x/8*x/8\n",
    "                        Bottlrneck(512,128,512, False),\n",
    "                        Bottlrneck(512,128,512, False),\n",
    "                        Bottlrneck(512,128,512, False),\n",
    "\n",
    "\n",
    "\n",
    "                        Bottlrneck(512,256,1024, True),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "\n",
    "\n",
    "\n",
    "                        Bottlrneck(1024,512,2048, True),\n",
    "                        Bottlrneck(2048,512,2048, False),\n",
    "                        Bottlrneck(2048,512,2048, False),\n",
    "\n",
    "                        torch.nn.AdaptiveAvgPool1d(1)#变成2048*1*1\n",
    "                    )\n",
    "                    self.classifer = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(2048,classes)#变成每类特征的信息\n",
    "                    )\n",
    "                    \n",
    "\n",
    "                def forward(self,x):\n",
    "                    x = self.features(x)\n",
    "                    x = x.view(-1,2048)\n",
    "                    x = self.classifer(x)\n",
    "                    return x\n",
    "\n",
    "            class NPEWithEmbedding(nn.Module):#这个网络只要是1维的2的倍数就行\n",
    "                def __init__(self,channels=3,beishu=4,canshu=2,build=zuko.flows.NSF,hidden_features=[128] * 3,activation=nn.ELU,transforms=3):\n",
    "                    super().__init__()\n",
    "\n",
    "                    self.npe = NPE(canshu, beishu, build=build, hidden_features=hidden_features,transforms=transforms, activation=activation)#用于\n",
    "                    self.embedding = ResNet(in_channels=channels,classes=beishu)\n",
    "\n",
    "                def forward(self, theta: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "                    #print(self.embedding(x).shape)\n",
    "\n",
    "                    return self.npe(theta, self.embedding(x))\n",
    "\n",
    "                def flow(self, x: torch.Tensor):  # -> flow对应原来的采样，因为他调用的就是flow\n",
    "                    return self.npe.flow(self.embedding(x))\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "            torch.manual_seed(2234)#重置参数，在循环里面可以保证可以复现\n",
    "            \n",
    "            estimator= NPEWithEmbedding(channels=4,canshu=12,beishu=beishu,build=liu,hidden_features=[num] * transfomr,transforms=trans,activation=act).cuda()#beishu是残差网络输出尺寸（npe的输入参数）\n",
    "            estimator.apply(weight_init)\n",
    "            \n",
    "            optimizer = optim.AdamW(estimator.parameters(), lr=f,weight_decay=weight_decay)#学习率！！！！！！！！！！！\n",
    "            #在优化器选项里添加正则化,weight_decay=0.01，l2正则化\n",
    "\n",
    "            scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.98)#学习率衰减\n",
    "            #https://zhuanlan.zhihu.com/p/363338422\n",
    "\n",
    "            step = GDStep(optimizer, clip=1.0)  # gradient descent step with gradient clipping,有了他不用optimizer.step\n",
    "            loss = NPELoss(estimator)\n",
    "\n",
    "            list_los=[]\n",
    "            list_losvail=[]\n",
    "        \n",
    "            with tqdm(range(2000), unit='epoch') as tq:#epoch\n",
    "                best_loss = np.inf#早停\n",
    "                best_model_weights = None\n",
    "                patience=50#10个周期不降就停\n",
    "                i=0\n",
    "                num=12000#总数\n",
    "                num_v=3000\n",
    "                datast=30#batch_size\n",
    "                nnum=num//datast\n",
    "                nnum_v=num_v//datast\n",
    "                for epoch in tq:\n",
    "                    #losses = torch.stack([\n",
    "                    #    step(loss(preprocess(theta).cuda(), x.cuda()))\n",
    "                    #    for theta, x in trainset # 这样写是遍历全部元素，实例那样是因为他是采样器\n",
    "                    #])\n",
    "\n",
    "                    pool = Pool(processes=56)\n",
    "                    results = pool.map(get_wave_plus_gaosnoise_t, range(num))\n",
    "                    all_x = torch.tensor(np.concatenate([x for x,y in results]).reshape(nnum,datast,4,4096*10),dtype=torch.float32)\n",
    "                    all_y = torch.tensor(np.concatenate([y for x,y in results]).reshape(nnum,datast,12),dtype=torch.float32)\n",
    "                    del results\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "\n",
    "                    pool = Pool(processes=56)\n",
    "                    results = pool.map(get_wave_plus_gaosnoise_t, range(num_v))\n",
    "                    all_x_vail = torch.tensor(np.concatenate([x for x,y in results]).reshape(nnum_v,datast,4,4096*10),dtype=torch.float32)\n",
    "                    all_y_vail = torch.tensor(np.concatenate([y for x,y in results]).reshape(nnum_v,datast,12),dtype=torch.float32)\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "\n",
    "                    del results\n",
    "                    \n",
    "                    estimator.train()\n",
    "                    losses = torch.stack([\n",
    "                        step(loss(preprocess(all_y[i]).cuda(), all_x[i].cuda()))\n",
    "                        for i in range(nnum) # 这样写是遍历全部元素，实例那样是因为他是采样器\n",
    "                    ])\n",
    "                    \n",
    "                    del all_x,all_y\n",
    "                    \n",
    "                    estimator.eval()\n",
    "                    with torch.no_grad():\n",
    "                        val_losses = torch.stack([\n",
    "                            loss(preprocess(all_y_vail[i]).cuda(), all_x_vail[i].cuda())\n",
    "                            for i in range(nnum_v)\n",
    "                        ])\n",
    "                    \n",
    "                    scheduler.step()#学习率衰减\n",
    "                    \n",
    "                    tq.set_postfix(loss=losses.mean().item(), val_loss=val_losses.mean().item())\n",
    "\n",
    "                    del all_x_vail,all_y_vail\n",
    "                    \n",
    "                    los=losses.mean().item()#类型不对，所以换名字\n",
    "                    losval=val_losses.mean().item()#类型不对，所以换名字\n",
    "                    \n",
    "                    list_los.append(los)#话损失函数图\n",
    "                    list_losvail.append(losval)#话损失函数图\n",
    "\n",
    "                    # 储存监视\n",
    "                    data1 = list_los\n",
    "                    data2 = list_losvail\n",
    "                    last= now\n",
    "                    now = datetime.now()\n",
    "                    # 打开一个文件用于写入\n",
    "                    file = open('/home/suntianyang/work5/ligo/net/data_train_t.txt', 'w')\n",
    "                    file.write('last_last:'+str(last) + '\\n')\n",
    "                    file.write('___last__:'+str(now) + '\\n')\n",
    "                    \n",
    "                    # 将每个元素写入文件中\n",
    "                    for item1, item2 in zip(data1, data2):\n",
    "                        file.write(str(item1) + ' ' + str(item2) + '\\n')\n",
    "                    \n",
    "                    # 关闭文件\n",
    "                    file.close()\n",
    "                    \n",
    "                    del losses,data1,data2\n",
    "                    \n",
    "                    \n",
    "                    process = psutil.Process()\n",
    "                    memory_info = process.memory_info()\n",
    "                    memory_usage = memory_info.rss / 1024/1024/1024  # 转换为KB\n",
    "                    print(f\"当前程序占用的内存：{memory_usage} GB\")\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.save(estimator.state_dict(),f'/home/suntianyang/work5/ligo/net/NPE_mid_t_hou.pth')\n",
    "                    \n",
    "                    if losval < best_loss:\n",
    "                        best_loss = losval\n",
    "                        epochs_without_improvement = 0\n",
    "                        best_model_weights = estimator.state_dict()\n",
    "                    else:\n",
    "                        epochs_without_improvement += 1\n",
    "                    \n",
    "                    \n",
    "                    # 如果验证集上的损失连续patience个epoch没有提高，则停止训练\n",
    "                    if epochs_without_improvement == patience:\n",
    "                        estimator.load_state_dict(best_model_weights)\n",
    "                        print('Early stopping at epoch {}...'.format(epoch-patience+1))\n",
    "                        break\n",
    "                        \n",
    "            torch.save(estimator.state_dict(),f'/home/suntianyang/work5/ligo/net/NPE_t.pth')\n",
    "            aaaaa.append('act{}学习率{},正则化{},,参数数目{},参数层数{},流层{},中间层{},最佳损失{},训练周期{}'.format(act,f,weight_decay,num,transfomr,trans,beishu,list_los[-1-10],len(list_los)-10))\n",
    "            print('act{}学习率{},正则化{},,参数数目{},参数层数{},流层{},中间层{},最佳损失{},训练周期{}'.format(act,f,weight_decay,num,transfomr,trans,beishu,list_los[-1-10],len(list_los)-10))\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9a47c-c445-4853-89d7-1487184d8c07",
   "metadata": {},
   "source": [
    "# 频域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e56e92-bf0a-4a5f-9a6a-9ff9f32af3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载网络\n",
    "\"3_trydata_train_(<class 'torch.nn.modules.activation.ReLU'>, 0.0001, 0, 4096, 7, 9, 512, 32)\"\n",
    "for act in [nn.ReLU]:\n",
    " for bins in [32]:\n",
    "  for f in [0.0001]:\n",
    "    for weight_decay in [0]:\n",
    "      for Dro in [np.nan]:\n",
    "       for liu in [zuko.flows.NSF]:\n",
    "        for transfomr in [7]:#,7\n",
    "         for num in [4096]:\n",
    "          for trans in [9]:\n",
    "           for beishu in [512]:\n",
    "            print('装载参数')\n",
    "            model = NPEWithEmbedding(channels=3,canshu=6,beishu=beishu,build=liu,hidden_features=[num] * transfomr,transforms=trans,activation=act,bins=bins).cuda()\n",
    "            model.load_state_dict(torch.load(\"/home/suntianyang/work3/net/net_3/3_try_(<class 'torch.nn.modules.activation.ReLU'>,\"+f' {f}, {weight_decay}, {bins}, {num}, {transfomr}, {trans}, {beishu}).pth'))\n",
    "            model.cuda()\n",
    "            model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e0de0-bd70-416d-a45f-3408a7f0bbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da6a6f-5eaf-4414-92ed-a210c72c8901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf6f37-bb64-4663-9ce8-f1a22f610bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#固定的参数\n",
    "calculator = Point_mass_lens_model()\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "\n",
    "def get_wave_plus_gaosnoise_f(sa):\n",
    "    hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "    while True:\n",
    "        epsilon=random.uniform(1e-6,0.5)*1e-6#MPc\n",
    "        dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(10,6000))#MPc\n",
    "        dl_samples=dl_distribution.rvs(size=1)\n",
    "        D_L=dl_samples[0][0]\n",
    "        dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(D_L,6000+D_L))#MPc\n",
    "        dl_samples=dl_distribution.rvs(size=1)\n",
    "        D_LS=dl_samples[0][0]-D_L#MPc\n",
    "        \n",
    "        M_L=random.uniform(1e3,1e5)#M\n",
    "        D_S=D_LS+D_L#MPc\n",
    "        z=f_dl_z(D_L)#MPc_z\n",
    "        z_s=f_dl_z(D_S)#MPc_z\n",
    "        M_LZ=M_L_Z(M_L,z)#M\n",
    "        xi_0=x_i_0(M_L,D_LS,D_L,D_S)\n",
    "\n",
    "        #print(calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "        #print(calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "        #print(calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "\n",
    "        dtt=calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        miu_pp=calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        miu_cc=calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S)))\n",
    "        if dtt<2.25e-3 or dtt>3.52 or miu_pp<1.7 or miu_pp>10.51 or miu_cc<-9.51 or miu_cc>-0.17:\n",
    "            continue\n",
    "        \n",
    "        #print(dtt,miu_pp,miu_cc)\n",
    "        result = types.FrequencySeries(calculator.F_f(f=hp_flens.sample_frequencies.data, M_LZ=M_LZ, epsilon=epsilon, D_L=D_L, xi_0=xi_0, D_s=D_S),delta_f=N_fs/N_s)\n",
    "        \n",
    "        tc=random.uniform(7,8)\n",
    "        mc_distribution=distributions.MchirpfromUniformMass1Mass2(mc=(5,80))\n",
    "        q_distribution=distributions.QfromUniformMass1Mass2(q=(0.5,2.0))#0.5-1\n",
    "        mc_samples = mc_distribution.rvs(size=1)\n",
    "        q_samples = q_distribution.rvs(size=1)\n",
    "        mc=mc_samples[0][0]\n",
    "        q=q_samples[0][0]\n",
    "        m1,m2=mc_q_to_m1_m2(mc,q)\n",
    "        distance=D_S\n",
    "        \n",
    "        sky_distribution = distributions.sky_location.UniformSky()\n",
    "        sky_samples=sky_distribution.rvs(size=1)\n",
    "        dec = sky_samples[0][0]#纬度\n",
    "        ra = sky_samples[0][1]#经度\n",
    "        \n",
    "        psi = random.uniform(0,np.pi*2)#偏振角ψ\n",
    "        inc=np.arccos(-1.0 + 2.0*np.random.rand())#倾角\n",
    "        coa_phase=random.uniform(0,np.pi*2)#合并相位\n",
    "        #IMRPhenomPv2，SEOBNRv4_opt,IMRPhenomTPHM\n",
    "        try:\n",
    "            hp, hc = get_td_waveform(approximant='IMRPhenomTPHM',\n",
    "                                     mass1=m1*(1+z_s),#红移质量1\n",
    "                                     mass2=m2*(1+z_s),#红移质量2\n",
    "                                     distance=distance,#距离，MPC\n",
    "                                     coa_phase=coa_phase,#合并相位\n",
    "                                     inclination=inc,#轨道和视线的夹角\n",
    "                                     spin1x=0,\n",
    "                                     spin1y=0,\n",
    "                                     spin1z=0,#自旋1\n",
    "                                     spin2x=0,\n",
    "                                     spin2y=0,\n",
    "                                     spin2z=0,#自旋2\n",
    "                                     eccentricity=0,#轨道偏心率\n",
    "                                     lambda1=0,#潮汐相，中子星有\n",
    "                                     lambda2=0,\n",
    "                                     delta_t=1.0/N_fs,\n",
    "                                     f_lower=30)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        fp_1, fc_1 = det_1.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_2, fc_2 = det_2.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_3, fc_3 = det_3.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_4, fc_4 = det_4.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        \n",
    "        ht_1 = fp_1*hp + fc_1*hc\n",
    "        ht_2 = fp_2*hp + fc_2*hc\n",
    "        ht_3 = fp_3*hp + fc_3*hc\n",
    "        ht_4 = fp_4*hp + fc_4*hc\n",
    "        \n",
    "        \n",
    "        ht_1.resize(N_s)\n",
    "        ht_1=ht_1.cyclic_time_shift(ht_1.start_time+tc)\n",
    "        ht_1.start_time=0\n",
    "        ht_2.resize(N_s)\n",
    "        ht_2=ht_2.cyclic_time_shift(ht_2.start_time+tc)\n",
    "        ht_2.start_time=0\n",
    "        ht_3.resize(N_s)\n",
    "        ht_3=ht_3.cyclic_time_shift(ht_3.start_time+tc)\n",
    "        ht_3.start_time=0\n",
    "        ht_4.resize(N_s)\n",
    "        ht_4=ht_4.cyclic_time_shift(ht_4.start_time+tc)\n",
    "        ht_4.start_time=0\n",
    "        \n",
    "        hp_f_1=ht_1.to_frequencyseries()\n",
    "        hp_flens_1=hp_f_1*result\n",
    "        hp_t_lens_1=hp_flens_1.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_2=ht_2.to_frequencyseries()\n",
    "        hp_flens_2=hp_f_2*result\n",
    "        hp_t_lens_2=hp_flens_2.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_3=ht_3.to_frequencyseries()\n",
    "        hp_flens_3=hp_f_3*result\n",
    "        hp_t_lens_3=hp_flens_3.to_timeseries()\n",
    "        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "        hp_f_4=ht_4.to_frequencyseries()\n",
    "        hp_flens_4=hp_f_4*result\n",
    "        hp_t_lens_4=hp_flens_4.to_timeseries()\n",
    "        \n",
    "        \n",
    "        #利用高斯 psd生成噪声：\n",
    "        noise_et1 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdl)\n",
    "        #添加非高斯噪声后要用welch方法估计psd——假设没有方法能合理的估计psd（psd中包含各种非高斯的干扰）\n",
    "        hp_t_lens_plusnoise_1=hp_t_lens_1.copy()\n",
    "        hp_t_lens_plusnoise_1.data+=noise_et1.data\n",
    "        \n",
    "        noise_et2 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdh)\n",
    "        hp_t_lens_plusnoise_2=hp_t_lens_2.copy()\n",
    "        hp_t_lens_plusnoise_2.data+=noise_et2.data\n",
    "        \n",
    "        noise_et3 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdv)\n",
    "        hp_t_lens_plusnoise_3=hp_t_lens_3.copy()\n",
    "        hp_t_lens_plusnoise_3.data+=noise_et3.data\n",
    "        \n",
    "        noise_et4 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdk)\n",
    "        hp_t_lens_plusnoise_4=hp_t_lens_4.copy()\n",
    "        hp_t_lens_plusnoise_4.data+=noise_et4.data\n",
    "        \n",
    "        snr1 = get_snr(hp_t_lens_1,T_obs,N_fs,psdl_snr.data)\n",
    "        snr2 = get_snr(hp_t_lens_2,T_obs,N_fs,psdh_snr.data)\n",
    "        snr3 = get_snr(hp_t_lens_3,T_obs,N_fs,psdv_snr.data)\n",
    "        snr4 = get_snr(hp_t_lens_4,T_obs,N_fs,psdk_snr.data)\n",
    "        snr=(snr1**2+snr2**2+snr3**2+snr4**2)**0.5\n",
    "        #print(snr)\n",
    "        \n",
    "        #print(snr)\n",
    "        if snr<16:\n",
    "            continue\n",
    "            \n",
    "        arr1 = np.concatenate((hp_t_lens_plusnoise_1.to_frequencyseries().real()*1e23,\n",
    "                              hp_t_lens_plusnoise_1.to_frequencyseries().imag()*1e23))\n",
    "        arr2 = np.concatenate((hp_t_lens_plusnoise_2.to_frequencyseries().real()*1e23,\n",
    "                              hp_t_lens_plusnoise_2.to_frequencyseries().imag()*1e23))\n",
    "        arr3 = np.concatenate((hp_t_lens_plusnoise_3.to_frequencyseries().real()*1e23,\n",
    "                              hp_t_lens_plusnoise_3.to_frequencyseries().imag()*1e23))\n",
    "        arr4 = np.concatenate((hp_t_lens_plusnoise_4.to_frequencyseries().real()*1e23,\n",
    "                              hp_t_lens_plusnoise_4.to_frequencyseries().imag()*1e23))\n",
    "        canshu=[epsilon,D_L,distance,M_L,mc,q,dec,ra,psi,inc,coa_phase,tc]#12个\n",
    "        \n",
    "        return [arr1, arr2,arr3,arr4],canshu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc3ccb-e45e-4836-aff4-7f2580b5ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adad=get_wave_plus_gaosnoise_f(11)\n",
    "plt.plot(adad[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b5314-eaf6-476a-b9eb-51022edacafe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#非采样器的\n",
    "torch.backends.cudnn.deterministic = True #禁用 cuDNN 的随机性，从而保证每次运行的结果都是相同的。\n",
    "\n",
    "aaaaa=[]\n",
    "\n",
    "import gc\n",
    "\n",
    "#  \"act<class 'torch.nn.modules.activation.ReLU'>学习率0.0003,正则化0.001,休眠率0.2,参数数目1024,参数层数7,流层9,中间层256,最佳损失-5.820067882537842,训练周期28\",\n",
    "#\"act<class 'torch.nn.modules.activation.ReLU'>学习率0.0003,正则化0,休眠率0.2,参数数目1024,参数层数7,流层9,中间层512,最佳损失-3.325531482696533,训练周期35\",\n",
    "for act in [nn.ReLU]:\n",
    "  for f in [0.0001]:\n",
    "    for weight_decay in [0]:\n",
    "       for liu in [zuko.flows.NSF]:\n",
    "        for transfomr in [7]:#,7\n",
    "         for num in [4096]:\n",
    "          for trans in [9]:\n",
    "           for beishu in [2048]:\n",
    "            \n",
    "            now= datetime.now()\n",
    "            def weight_init(m):\n",
    "                if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "                    nn.init.xavier_uniform_(m.weight.data)#kaiming_normal_///xavier_uniform_\n",
    "                    nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "            class Bottlrneck(torch.nn.Module):\n",
    "                def __init__(self,In_channel,Med_channel,Out_channel,downsample=False):\n",
    "                    super(Bottlrneck, self).__init__()\n",
    "                    self.stride = 1\n",
    "                    if downsample == True:\n",
    "                        self.stride = 2\n",
    "                    #在这里添加BatchNorm1d和Dropout是最合适的\n",
    "                    self.layer = torch.nn.Sequential(\n",
    "                        torch.nn.Conv1d(In_channel, Med_channel, 1, self.stride),\n",
    "                        torch.nn.BatchNorm1d(Med_channel),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Conv1d(Med_channel, Med_channel, 3, padding=1),\n",
    "                        torch.nn.BatchNorm1d(Med_channel),\n",
    "                        #torch.nn.ReLU(),\n",
    "                        torch.nn.Conv1d(Med_channel, Out_channel, 1),\n",
    "                        torch.nn.BatchNorm1d(Out_channel),\n",
    "                        #torch.nn.ReLU(),\n",
    "                    )\n",
    "\n",
    "                    if In_channel != Out_channel:\n",
    "                        self.res_layer = torch.nn.Conv1d(In_channel, Out_channel,1,self.stride)\n",
    "                    else:\n",
    "                        self.res_layer = None\n",
    "\n",
    "                    self.jia_relu=torch.nn.Sequential(torch.nn.ReLU())\n",
    "\n",
    "                def forward(self,x):\n",
    "                    if self.res_layer is not None:\n",
    "                        residual = self.res_layer(x)\n",
    "                    else:\n",
    "                        residual = x\n",
    "                    return self.jia_relu(self.layer(x)+residual)\n",
    "                \n",
    "                def forward(self,x):\n",
    "                    if self.res_layer is not None:\n",
    "                        residual = self.res_layer(x)\n",
    "                    else:\n",
    "                        residual = x\n",
    "                    return self.layer(x)+residual\n",
    "\n",
    "            class ResNet(torch.nn.Module):\n",
    "                def __init__(self,in_channels=1,classes=5):\n",
    "                    super(ResNet, self).__init__()\n",
    "                    self.features = torch.nn.Sequential(\n",
    "                        torch.nn.Conv1d(in_channels,64,kernel_size=7,stride=2,padding=3),##in_channels*x*x--->64*x/2*x/2\n",
    "                        torch.nn.MaxPool1d(3,2,1),#池化——64*x/4*x/4\n",
    "\n",
    "                        Bottlrneck(64,64,256,False),\n",
    "                        Bottlrneck(256,64,256,False),\n",
    "                        Bottlrneck(256,64,256,False),#256*x/4*x/4\n",
    "\n",
    "\n",
    "\n",
    "                        Bottlrneck(256,128,512, True),#True代表卷积步长为2————256*x/8*x/8\n",
    "                        Bottlrneck(512,128,512, False),\n",
    "                        Bottlrneck(512,128,512, False),\n",
    "                        Bottlrneck(512,128,512, False),\n",
    "\n",
    "\n",
    "\n",
    "                        Bottlrneck(512,256,1024, True),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "                        Bottlrneck(1024,256,1024, False),\n",
    "\n",
    "\n",
    "\n",
    "                        Bottlrneck(1024,512,2048, True),\n",
    "                        Bottlrneck(2048,512,2048, False),\n",
    "                        Bottlrneck(2048,512,2048, False),\n",
    "\n",
    "                        torch.nn.AdaptiveAvgPool1d(1)#变成2048*1*1\n",
    "                    )\n",
    "                    self.classifer = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(2048,classes)#变成每类特征的信息\n",
    "                    )\n",
    "                    \n",
    "\n",
    "                def forward(self,x):\n",
    "                    x = self.features(x)\n",
    "                    x = x.view(-1,2048)\n",
    "                    x = self.classifer(x)\n",
    "                    return x\n",
    "\n",
    "            class NPEWithEmbedding(nn.Module):#这个网络只要是1维的2的倍数就行\n",
    "                def __init__(self,channels=3,beishu=4,canshu=2,build=zuko.flows.NSF,hidden_features=[128] * 3,activation=nn.ELU,transforms=3):\n",
    "                    super().__init__()\n",
    "\n",
    "                    self.npe = NPE(canshu, beishu, build=build, hidden_features=hidden_features,transforms=transforms, activation=activation)#用于\n",
    "                    self.embedding = ResNet(in_channels=channels,classes=beishu)\n",
    "\n",
    "                def forward(self, theta: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "                    #print(self.embedding(x).shape)\n",
    "\n",
    "                    return self.npe(theta, self.embedding(x))\n",
    "\n",
    "                def flow(self, x: torch.Tensor):  # -> flow对应原来的采样，因为他调用的就是flow\n",
    "                    return self.npe.flow(self.embedding(x))\n",
    "\n",
    "            torch.manual_seed(2234)#重置参数，在循环里面可以保证可以复现\n",
    "            \n",
    "            estimator= NPEWithEmbedding(channels=4,canshu=12,beishu=beishu,build=liu,hidden_features=[num] * transfomr,transforms=trans,activation=act).cuda()#beishu是残差网络输出尺寸（npe的输入参数）\n",
    "            estimator.apply(weight_init)\n",
    "            \n",
    "            optimizer = optim.AdamW(estimator.parameters(), lr=f,weight_decay=weight_decay)#学习率！！！！！！！！！！！\n",
    "            #在优化器选项里添加正则化,weight_decay=0.01，l2正则化\n",
    "\n",
    "            scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.98)#学习率衰减\n",
    "            #https://zhuanlan.zhihu.com/p/363338422\n",
    "\n",
    "            step = GDStep(optimizer, clip=1.0)  # gradient descent step with gradient clipping,有了他不用optimizer.step\n",
    "            loss = NPELoss(estimator)\n",
    "\n",
    "            list_los = []  # 用于存储第一列数据\n",
    "            list_losvail = []  # 用于存储第二列数据\n",
    "            \n",
    "            with tqdm(range(2000), unit='epoch') as tq:#epoch\n",
    "                best_loss = np.inf#早停\n",
    "                best_model_weights = None\n",
    "                patience=50#10个周期不降就停\n",
    "                i=0\n",
    "                i_numca=0\n",
    "                num=12000#总数\n",
    "                num_v=3000\n",
    "                datast=30#batch_size\n",
    "                nnum=num//datast\n",
    "                nnum_v=num_v//datast\n",
    "                for epoch in tq:\n",
    "                    #losses = torch.stack([\n",
    "                    #    step(loss(preprocess(theta).cuda(), x.cuda()))\n",
    "                    #    for theta, x in trainset # 这样写是遍历全部元素，实例那样是因为他是采样器\n",
    "                    #])\n",
    "\n",
    "                    pool = Pool(processes=56)\n",
    "                    results = pool.map(get_wave_plus_gaosnoise_f, range(num))\n",
    "                    all_x = torch.tensor(np.concatenate([x for x,y in results]).reshape(nnum,datast,4,T_obs*4096+2),dtype=torch.float32)\n",
    "                    all_y = torch.tensor(np.concatenate([y for x,y in results]).reshape(nnum,datast,12),dtype=torch.float32)\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "                    \n",
    "                    del results\n",
    "                    \n",
    "                    pool = Pool(processes=56)\n",
    "                    results = pool.map(get_wave_plus_gaosnoise_f, range(num_v))\n",
    "                    all_x_vail = torch.tensor(np.concatenate([x for x,y in results]).reshape(nnum_v,datast,4,T_obs*4096+2),dtype=torch.float32)\n",
    "                    all_y_vail = torch.tensor(np.concatenate([y for x,y in results]).reshape(nnum_v,datast,12),dtype=torch.float32)\n",
    "\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "\n",
    "                    del results\n",
    "                    \n",
    "                    estimator.train()\n",
    "                    losses = torch.stack([\n",
    "                        step(loss(preprocess(all_y[i]).cuda(), all_x[i].cuda()))\n",
    "                        for i in range(nnum) # 这样写是遍历全部元素，实例那样是因为他是采样器\n",
    "                    ])\n",
    "                    \n",
    "                    del all_x,all_y\n",
    "                    \n",
    "                    estimator.eval()\n",
    "                    with torch.no_grad():\n",
    "                        val_losses = torch.stack([\n",
    "                            loss(preprocess(all_y_vail[i]).cuda(), all_x_vail[i].cuda())\n",
    "                            for i in range(nnum_v)\n",
    "                        ])\n",
    "                    \n",
    "                    scheduler.step()#学习率衰减\n",
    "                    \n",
    "                    tq.set_postfix(loss=losses.mean().item(), val_loss=val_losses.mean().item())\n",
    "\n",
    "                    del all_x_vail,all_y_vail\n",
    "                    \n",
    "                    los=losses.mean().item()#类型不对，所以换名字\n",
    "                    losval=val_losses.mean().item()#类型不对，所以换名字\n",
    "                    \n",
    "                    list_los.append(los)#话损失函数图\n",
    "                    list_losvail.append(losval)#话损失函数图\n",
    "\n",
    "                    # 储存监视\n",
    "                    data1 = list_los\n",
    "                    data2 = list_losvail\n",
    "                    last= now\n",
    "                    now = datetime.now()\n",
    "                    # 打开一个文件用于写入\n",
    "                    file = open('/home/suntianyang/work5/ligo/net/data_train_f.txt', 'w')\n",
    "                    file.write('last_last:'+str(last) + '\\n')\n",
    "                    file.write('___last__:'+str(now) + '\\n')\n",
    "                    \n",
    "                    # 将每个元素写入文件中\n",
    "                    for item1, item2 in zip(data1, data2):\n",
    "                        file.write(str(item1) + ' ' + str(item2) + '\\n')\n",
    "                    \n",
    "                    # 关闭文件\n",
    "                    file.close()\n",
    "                    \n",
    "                    del losses,data1,data2\n",
    "                    \n",
    "                    \n",
    "                    process = psutil.Process()\n",
    "                    memory_info = process.memory_info()\n",
    "                    memory_usage = memory_info.rss / 1024/1024/1024  # 转换为KB\n",
    "                    print(f\"当前程序占用的内存：{memory_usage} GB\")\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    torch.save(estimator.state_dict(),f'/home/suntianyang/work5/ligo/net/NPE_mid_f_hou.pth')\n",
    "                    \n",
    "                    if losval < best_loss:\n",
    "                        best_loss = losval\n",
    "                        epochs_without_improvement = 0\n",
    "                        best_model_weights = estimator.state_dict()\n",
    "                    else:\n",
    "                        epochs_without_improvement += 1\n",
    "                    \n",
    "                    \n",
    "                    # 如果验证集上的损失连续patience个epoch没有提高，则停止训练\n",
    "                    if epochs_without_improvement == patience:\n",
    "                        estimator.load_state_dict(best_model_weights)\n",
    "                        print('Early stopping at epoch {}...'.format(epoch-patience+1))\n",
    "                        break\n",
    "\n",
    "            torch.save(estimator.state_dict(),f'/home/suntianyang/work5/ligo/net/NPE_f.pth')\n",
    "            aaaaa.append('act{}学习率{},正则化{},,参数数目{},参数层数{},流层{},中间层{},最佳损失{},训练周期{}'.format(act,f,weight_decay,num,transfomr,trans,beishu,list_los[-1-10],len(list_los)-10))\n",
    "            print('act{}学习率{},正则化{},,参数数目{},参数层数{},流层{},中间层{},最佳损失{},训练周期{}'.format(act,f,weight_decay,num,transfomr,trans,beishu,list_los[-1-10],len(list_los)-10))\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d8171-8d05-485b-8d81-f6b005d9cfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
