{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78acead6-7997-48e2-8e21-1ef616ff4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1024——glitch生成\n",
    "import matplotlib.pyplot as pp\n",
    "import matplotlib.pyplot as plt\n",
    "from pycbc.waveform import get_td_waveform,get_fd_waveform\n",
    "from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "from pycbc.filter import sigma\n",
    "from pycbc import types\n",
    "from pycbc.detector import Detector\n",
    "from pycbc.filter import matched_filter\n",
    "import pycbc\n",
    "from pycbc.psd import welch\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "from pycbc import waveform\n",
    "import scipy\n",
    "import h5py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from pycbc import distributions\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from gwpy.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e542fd-9fea-4bae-88b0-7abc81b151d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "#函数定义\n",
    "def z_to_d_ang(z, H0, Omega_m, Omega_Lambda):#输入红移输出直径距离\n",
    "    c = 299792.458  # 光速，单位：km/s\n",
    "    # 定义被积函数\n",
    "    integrand = lambda z: 1 / np.sqrt(Omega_m * (1 + z)**3 + Omega_Lambda)\n",
    "    # 积分计算\n",
    "    result, _ = quad(integrand, 0, z)\n",
    "    # 计算距离\n",
    "    distance = c / (H0 * (1+z) )* result\n",
    "    return distance\n",
    "\n",
    "\n",
    "def zl_zs_to_dsl_ang(zl,zs, H0, Omega_m, Omega_Lambda):#输入红移、输出直径距离\n",
    "    c = 299792.458  # 光速，单位：km/s\n",
    "    integrand = lambda z: 1 / np.sqrt(Omega_m * (1 + z)**3 + Omega_Lambda)\n",
    "    result, _ = quad(integrand, zl, zs)\n",
    "    distance = c / (H0 * (1+zs) )* result\n",
    "    return distance\n",
    "\n",
    "\n",
    "def d_ang_to_dl(D_ang,z):#输入角直径距离、输出光度距离\n",
    "    return D_ang*(1+z)**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47745f",
   "metadata": {},
   "source": [
    "# 点质量透镜模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6e4667-e943-4634-a076-ea1e3f802bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Point_mass_lens_model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def F_f(self, f, M_LZ, epsilon, D_L, xi_0, D_s):\n",
    "        return np.abs(self.miu_p(self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))**0.5 - \\\n",
    "            1j * np.abs(self.miu_c(self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))**0.5 * \\\n",
    "            np.exp(2j * np.pi * f * self.dt(M_LZ, self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))\n",
    "    \n",
    "    def miu_p(self, y, beta):\n",
    "        return 0.5 + (y**2 + 2) / (2 * y * beta)\n",
    "    \n",
    "    def miu_c(self, y, beta):\n",
    "        return 0.5 - (y**2 + 2) / (2 * y * beta)\n",
    "    #G:m³/kg·s²\n",
    "    def dt(self, M_LZ, y, beta):#单位s\n",
    "        return 4 * M_LZ*(y * beta / 2 + np.log((beta + y) / (beta - y))) * scipy.constants.G / scipy.constants.c**3 *(1.989e30)\n",
    "    \n",
    "    def beta(self, y):\n",
    "        return (y**2 + 4)**0.5\n",
    "    \n",
    "    def y(self, epsilon, D_L, xi_0, D_s):\n",
    "        return epsilon * D_L / xi_0 / D_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y,SIS的μ_+-,Δt,F(f)PM的μ+-,Δt,F(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534024e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 4.5\n",
    "def yy_ll(epsilon, D_L, xi_0, D_s):\n",
    "    return epsilon * D_L / xi_0 / D_s\n",
    "    \n",
    "def miu_p_sis(y_l):\n",
    "    return 1+1/y_l\n",
    "\n",
    "def miu_c_sis(y_l):\n",
    "    return -1+1/y_l\n",
    "    \n",
    "def det_t_sis(M_L,y_l,zl):\n",
    "    return 8*M_L*(1+zl)*y_l* scipy.constants.G / scipy.constants.c**3 *(1.989e30)\n",
    "    \n",
    "    \n",
    "def miu_p_pm(y_l):\n",
    "    return 1/2+(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
    "\n",
    "def miu_c_pm(y_l):\n",
    "    return 1/2-(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
    "    \n",
    "def det_t_pm(M_L,y_l,zl):\n",
    "    return 2*M_L*(1+zl)*(y_l*(y_l**2+4)**0.5+2*np.log(((y_l**2+4)**0.5+y_l)/((y_l**2+4)**0.5-y_l)))* scipy.constants.G / scipy.constants.c**3 *(1.989e30)\n",
    "    \n",
    "    \n",
    "def PM_model(f, miu_p, miu_c, det_t):\n",
    "    return np.abs(miu_p)**0.5 - 1j * np.abs(miu_c)**0.5 *  np.exp(2j * np.pi * f * det_t)\n",
    "\n",
    "def SIS_model(f, miu_p, miu_c, det_t,y_l):\n",
    "    if y_l<1:\n",
    "        return np.abs(miu_p)**0.5 - 1j * np.abs(miu_c)**0.5 *  np.exp(2j * np.pi * f * det_t)\n",
    "    else:\n",
    "        return np.abs(miu_p)**0.5 \n",
    "    \n",
    "def y_lens(epsilon, D_L, xi_0, D_s):\n",
    "    return epsilon * D_L / xi_0 / D_s\n",
    "    \n",
    "def M_L_Z(M_L,z):\n",
    "    return M_L*(1+z)\n",
    "    \n",
    "def x_i_0(M_L,D_LS,D_L,D_S): #G:m³/kg·s² #m^1 kg^-1 Mc^1  Mpc^1 单位转化成MPc,,,,1.989×1030 千克,,,3.0857E+22\n",
    "    return ((4*scipy.constants.G*M_L/scipy.constants.c**2)*(D_LS*D_L/D_S) /(3.0857e22)*(1.989e30))**0.5\n",
    "\n",
    "def mc_q_to_m1_m2(mc,q):\n",
    "    m1=(mc**5*(1+q)/q**3)**(1/5)\n",
    "    m2=m1*q\n",
    "    return m1,m2\n",
    "\n",
    "\n",
    "def get_snr(data,T_obs,fs,psd):\n",
    "    #波形、1、频率、psd\n",
    "    N = T_obs*fs\n",
    "    delta_f = 1.0/T_obs\n",
    "    delta_t = 1.0/fs\n",
    "\n",
    "#     win = tukey(N,alpha=1.0/8.0)\n",
    "    idx = np.argwhere(psd==0.0)\n",
    "    psd[idx] = 1e300\n",
    "\n",
    "    xf = np.fft.rfft(data)*delta_t\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(np.real(xf))\n",
    "    #plt.plot(np.imag(xf))\n",
    "    SNRsq = 4.0*np.sum((np.abs(xf)**2)/psd)*delta_f\n",
    "    return np.sqrt(SNRsq)\n",
    "\n",
    "@np.vectorize\n",
    "def gw_waveform(f,A,D,m1,m2,t_c,psi_c,z):\n",
    "    M=m1+m2\n",
    "    qq=m1*m2/M**2\n",
    "    Mz=(1+z)*M\n",
    "    Mc=qq**(3/5)*Mz\n",
    "    f_cut=1/(6**(3/2)*np.pi*Mz) / scipy.constants.G * scipy.constants.c**3 /(1.989e30)\n",
    "    def fi(f,t_c,psi_c,qq,Mc):\n",
    "        return 2*np.pi*f*t_c-psi_c-np.pi/4+3/4*(8*np.pi*Mc*f)**(-5/3)*(1+20/9*(743/336+11/4*qq)*(np.pi*Mz*f)**(2/3)-16*np.pi*(np.pi*Mz*f))\n",
    "    if f_cut<f:\n",
    "        return 0\n",
    "    else:\n",
    "        return A/D*Mc**(5/6)*f**(-7/6)*np.exp(1j*fi(f,t_c,psi_c,qq,Mc))*1e-19/0.27\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e57278-9cef-4283-9086-9fc5c117cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_to_y_sis(y_l,I):\n",
    "    return I-miu_c_sis(y_l)/miu_p_sis(y_l)\n",
    "\n",
    "def I_to_y_pm(y_l,I):\n",
    "    return I+miu_c_pm(y_l)/miu_p_pm(y_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db357dbc-2041-4aea-b7b0-974c9c2634a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#固定的参数\n",
    "calculator = Point_mass_lens_model()\n",
    "T_obs=10\n",
    "N_fs=4096#采样率为4096Hz\n",
    "N_s=T_obs*N_fs#对应时域为10s\n",
    "\n",
    "flen = round(N_s/2)+1\n",
    "delta_f = 1.0 / T_obs\n",
    "delta_t=1/N_fs\n",
    "f_low=30\n",
    "flow=30\n",
    "\n",
    "tsamples = int(T_obs / delta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e63e916-2c6a-4c77-a3db-1a4fc515d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开txt文件以读取内容\n",
    "with open('/home/suntianyang/work5/ligo/aligo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdh = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdh.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdh.sample_frequencies<f_low]=0\n",
    "psdh.data=y_new\n",
    "psdh_snr = psdh.copy()\n",
    "\n",
    "# 打开txt文件以读取内容\n",
    "with open('/home/suntianyang/work5/ligo/aligo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdl = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdl.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdl.sample_frequencies<f_low]=0\n",
    "psdl.data=y_new\n",
    "psdl_snr = psdl.copy()\n",
    "\n",
    "# 打开txt文件以读取内容\n",
    "with open('/home/suntianyang/work5/ligo/avirgo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdv = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdv.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdv.sample_frequencies<f_low]=0\n",
    "psdv.data=y_new\n",
    "psdv_snr = psdv.copy()\n",
    "\n",
    "# 打开txt文件以读取内容\n",
    "with open('/home/suntianyang/work5/ligo/k1_o4_high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdk = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdk.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdk.sample_frequencies<f_low]=0\n",
    "psdk.data=y_new\n",
    "psdk_snr = psdk.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc81c64-0364-41a3-82f3-2673c5da8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as nn_utils\n",
    "import zuko\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lampe.data import JointLoader\n",
    "from lampe.inference import NPE, NPELoss\n",
    "from lampe.plots import nice_rc, corner, mark_point\n",
    "from lampe.utils import GDStep\n",
    "from lampe.data import H5Dataset\n",
    "from lampe.diagnostics import expected_coverage_mc\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7abd67-d683-48a0-b6e5-c3455c382b56",
   "metadata": {},
   "source": [
    "\n",
    "# 这个是那一堆点的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356766c1-b3bd-42e5-9bc7-496419e9532e",
   "metadata": {},
   "source": [
    "# PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed47d661-7b8b-490f-9dc0-35761bb83382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-062413ee05f4>:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1/2-(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
      "<ipython-input-9-062413ee05f4>:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1/2+(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
      "<ipython-input-9-062413ee05f4>:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  I=np.abs(miu_c_pm(y_l)/miu_p_pm(y_l))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9edf5cb940>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def miu_p_pm(y_l):\n",
    "    return 1/2+(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
    "\n",
    "def miu_c_pm(y_l):\n",
    "    return 1/2-(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "y_l=np.linspace(0,100,10000)\n",
    "I=np.abs(miu_c_pm(y_l)/miu_p_pm(y_l))\n",
    "I[-1]=0\n",
    "\n",
    "f_I_to_y_PM=scipy.interpolate.interp1d(I,y_l,kind='linear')\n",
    "xnew=np.linspace(0,1.0,10000)   \n",
    "ynew=f_I_to_y_PM(xnew)\n",
    "plt.plot(xnew,ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d00ae-5565-406f-a533-820760d9822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNINGWARNINGWARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      "WARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNINGWARNING\n",
      "\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNINGWARNING\n",
      "WARNINGWARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      "\n",
      "\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING"
     ]
    }
   ],
   "source": [
    "def miu_p_pm(y_l):\n",
    "    return 1/2+(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
    "\n",
    "def miu_c_pm(y_l):\n",
    "    return 1/2-(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
    "\n",
    "#固定的参数\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "Z_L=0\n",
    "for I in np.linspace(0,1,20):\n",
    "    for dtt in np.linspace(0,0.2,20):\n",
    "        y_l=f_I_to_y_PM(I)\n",
    "        miu_pp=miu_p_pm(y_l)\n",
    "        miu_cc=miu_c_pm(y_l)\n",
    "        I_tt=np.abs(miu_cc)/np.abs(miu_pp)\n",
    "        for SNRRR in [8,12]:\n",
    "            hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "            result = types.FrequencySeries(PM_model(hp_flens.sample_frequencies.data,miu_pp, miu_cc, dtt),delta_f=N_fs/N_s)\n",
    "            def get_wave_plus_gaosnoise_t_gen(saaaa):\n",
    "                while True:\n",
    "                    tc=random.uniform(7,8)\n",
    "                    mc_distribution=distributions.MchirpfromUniformMass1Mass2(mc=(5,80))\n",
    "                    q_distribution=distributions.QfromUniformMass1Mass2(q=(0.5,2.0))#0.5-1\n",
    "                    mc_samples = mc_distribution.rvs(size=1)\n",
    "                    q_samples = q_distribution.rvs(size=1)\n",
    "                    mc=mc_samples[0][0]\n",
    "                    q=q_samples[0][0]\n",
    "                    m1,m2=mc_q_to_m1_m2(mc,q)\n",
    "\n",
    "                    zs_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(Z_L,1.0))#MPc\n",
    "                    zs_samples=zs_distribution.rvs(size=1)\n",
    "                    Z_s=zs_samples[0][0]\n",
    "                    D_S=z_to_d_ang(Z_s,70,0.3,0.7)\n",
    "                    \n",
    "                    distance=d_ang_to_dl(D_S,Z_s)\n",
    "\n",
    "                    sky_distribution = distributions.sky_location.UniformSky()\n",
    "                    sky_samples=sky_distribution.rvs(size=1)\n",
    "                    dec = sky_samples[0][0]#纬度\n",
    "                    ra = sky_samples[0][1]#经度\n",
    "\n",
    "                    psi = random.uniform(0,np.pi*2)#偏振角ψ\n",
    "                    inc=np.arccos(-1.0 + 2.0*np.random.rand())#倾角\n",
    "                    coa_phase=random.uniform(0,np.pi*2)#合并相位\n",
    "                    #IMRPhenomPv2，SEOBNRv4_opt,IMRPhenomTPHM\n",
    "\n",
    "\n",
    "##try 后与PM无本质区别, 除了保存的文件名不同.\n",
    "                    try:\n",
    "                        hp, hc = get_td_waveform(approximant='IMRPhenomTPHM',\n",
    "                                                 mass1=m1*(1+Z_s),#红移质量1\n",
    "                                                 mass2=m2*(1+Z_s),#红移质量2\n",
    "                                                 distance=distance,#距离，MPC\n",
    "                                                 coa_phase=coa_phase,#合并相位\n",
    "                                                 inclination=inc,#轨道和视线的夹角\n",
    "                                                 spin1x=0,\n",
    "                                                 spin1y=0,\n",
    "                                                 spin1z=0,#自旋1\n",
    "                                                 spin2x=0,\n",
    "                                                 spin2y=0,\n",
    "                                                 spin2z=0,#自旋2\n",
    "                                                 eccentricity=0,#轨道偏心率\n",
    "                                                 lambda1=0,#潮汐相，中子星有\n",
    "                                                 lambda2=0,\n",
    "                                                 delta_t=1.0/N_fs,\n",
    "                                                 f_lower=30)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    fp_1, fc_1 = det_1.antenna_pattern(\n",
    "                                    right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "                    fp_2, fc_2 = det_2.antenna_pattern(\n",
    "                                    right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "                    fp_3, fc_3 = det_3.antenna_pattern(\n",
    "                                    right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "                    fp_4, fc_4 = det_4.antenna_pattern(\n",
    "                                    right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "\n",
    "                    ht_1 = fp_1*hp + fc_1*hc\n",
    "                    ht_2 = fp_2*hp + fc_2*hc\n",
    "                    ht_3 = fp_3*hp + fc_3*hc\n",
    "                    ht_4 = fp_4*hp + fc_4*hc\n",
    "\n",
    "\n",
    "                    ht_1.resize(N_s)\n",
    "                    ht_1=ht_1.cyclic_time_shift(ht_1.start_time+tc)\n",
    "                    ht_1.start_time=0\n",
    "                    ht_2.resize(N_s)\n",
    "                    ht_2=ht_2.cyclic_time_shift(ht_2.start_time+tc)\n",
    "                    ht_2.start_time=0\n",
    "                    ht_3.resize(N_s)\n",
    "                    ht_3=ht_3.cyclic_time_shift(ht_3.start_time+tc)\n",
    "                    ht_3.start_time=0\n",
    "                    ht_4.resize(N_s)\n",
    "                    ht_4=ht_4.cyclic_time_shift(ht_4.start_time+tc)\n",
    "                    ht_4.start_time=0\n",
    "\n",
    "                    hp_f_1=ht_1.to_frequencyseries()\n",
    "                    hp_flens_1=hp_f_1*result\n",
    "                    hp_t_lens_1=hp_flens_1.to_timeseries()\n",
    "                    #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "                    hp_f_2=ht_2.to_frequencyseries()\n",
    "                    hp_flens_2=hp_f_2*result\n",
    "                    hp_t_lens_2=hp_flens_2.to_timeseries()\n",
    "                    #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "                    hp_f_3=ht_3.to_frequencyseries()\n",
    "                    hp_flens_3=hp_f_3*result\n",
    "                    hp_t_lens_3=hp_flens_3.to_timeseries()\n",
    "                    #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "                    hp_f_4=ht_4.to_frequencyseries()\n",
    "                    hp_flens_4=hp_f_4*result\n",
    "                    hp_t_lens_4=hp_flens_4.to_timeseries()\n",
    "\n",
    "\n",
    "                    #利用高斯 psd生成噪声：\n",
    "                    #添加非高斯噪声后要用welch方法估计psd——假设没有方法能合理的估计psd（psd中包含各种非高斯的干扰）\n",
    "                    noise_et1 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdl)\n",
    "                    hp_t_lens_plusnoise_1=hp_t_lens_1.copy()\n",
    "                    hp_t_lens_plusnoise_1.data+=noise_et1.data\n",
    "\n",
    "                    noise_et2 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdh)\n",
    "                    hp_t_lens_plusnoise_2=hp_t_lens_2.copy()\n",
    "                    hp_t_lens_plusnoise_2.data+=noise_et2.data\n",
    "\n",
    "                    noise_et3 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdv)\n",
    "                    hp_t_lens_plusnoise_3=hp_t_lens_3.copy()\n",
    "                    hp_t_lens_plusnoise_3.data+=noise_et3.data\n",
    "\n",
    "                    noise_et4 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdk)\n",
    "                    hp_t_lens_plusnoise_4=hp_t_lens_4.copy()\n",
    "                    hp_t_lens_plusnoise_4.data+=noise_et4.data\n",
    "\n",
    "                    snr1 = get_snr(hp_t_lens_1,T_obs,N_fs,psdl_snr.data)\n",
    "                    snr2 = get_snr(hp_t_lens_2,T_obs,N_fs,psdh_snr.data)\n",
    "                    snr3 = get_snr(hp_t_lens_3,T_obs,N_fs,psdv_snr.data)\n",
    "                    snr4 = get_snr(hp_t_lens_4,T_obs,N_fs,psdk_snr.data)\n",
    "                    snr=(snr1**2+snr2**2+snr3**2+snr4**2)**0.5\n",
    "                    #print(snr)\n",
    "\n",
    "                    #print(snr,D_S,D_LS,D_L,distance)\n",
    "                    if snr<(SNRRR-2) or snr>(SNRRR+2):\n",
    "                        continue\n",
    "\n",
    "                    L11data = (hp_t_lens_plusnoise_1.to_frequencyseries() / psdl_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "                    H11data = (hp_t_lens_plusnoise_2.to_frequencyseries() / psdh_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "                    V11data = (hp_t_lens_plusnoise_3.to_frequencyseries() / psdv_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "                    K11data = (hp_t_lens_plusnoise_4.to_frequencyseries() / psdk_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "\n",
    "                    canshu=[dtt,I_tt]#12个\n",
    "\n",
    "                    return [L11data.data,H11data.data,V11data.data,K11data.data],[1.0],[snr,m1+m2],canshu\n",
    "\n",
    "            def get_wave_plus_gaosnoise_t_gen_cai(data):\n",
    "                nnnyyu=2**5\n",
    "                samples_all=torch.zeros((data.shape[0],2,nnnyyu))\n",
    "                for i in range(data.shape[0]):\n",
    "                    estimator.eval()\n",
    "                    with torch.no_grad():\n",
    "                        samples = estimator.flow(data[i].reshape(1,4,40960).cuda()).sample((nnnyyu,)).cpu()\n",
    "                        samples = postprocess(samples)\n",
    "\n",
    "                    samples_all[i,0,:]=samples[:,0,0]\n",
    "                    samples_all[i,1,:]=samples[:,0,1]\n",
    "                return samples_all\n",
    "\n",
    "\n",
    "            pool = Pool(processes=56)\n",
    "            results = pool.map(get_wave_plus_gaosnoise_t_gen, [0.5]*100)\n",
    "            all_x_vail_data = torch.tensor(np.concatenate([x for x,y,z,u in results]).reshape(100,4,40960),dtype=torch.float32)\n",
    "            #all_x_vail=get_wave_plus_gaosnoise_t_gen_cai(all_x_vail_data).reshape(100,2,2**5)\n",
    "            all_y_vail = torch.tensor(np.concatenate([y for x,y,z,u in results]).reshape(100,1),dtype=torch.float32)#标签-1\n",
    "            all_z_vail = torch.tensor(np.concatenate([z for x,y,z,u in results]).reshape(100,2),dtype=torch.float32)#参数\n",
    "            all_u_vail = torch.tensor(np.concatenate([u for x,y,z,u in results]).reshape(100,2),dtype=torch.float32)#参数\n",
    "\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            \n",
    "            np.save(f'./data/I_dt/test_PM_data_{I}_{dtt}_{SNRRR}.npy',all_x_vail_data)\n",
    "            #np.save(f'./data/I_dt/test_PM_data__{I}_{y_l}_{SNRRR}.npy',all_x_vail)\n",
    "            np.save(f'./data/I_dt/test_PM_label_{I}_{dtt}_{SNRRR}.npy',all_y_vail)\n",
    "            np.save(f'./data/I_dt/test_PM_err_{I}_{dtt}_{SNRRR}.npy',all_z_vail)    \n",
    "            np.save(f'./data/I_dt/test_PM_canshu_{I}_{dtt}_{SNRRR}.npy',all_u_vail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd390cb5-56e1-4364-b7c3-3d13947e7dee",
   "metadata": {},
   "source": [
    "# SIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35436993-40b8-4c2e-893d-506133bf5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_to_y_SIS(I):\n",
    "    y1=(1+I)/(1-I)\n",
    "    y2=(1-I)/(1+I)\n",
    "    return y1,y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505668e-45c2-40cf-85f3-2060fefdacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_L=0\n",
    "xx=[]\n",
    "yy=[]\n",
    "asas=0\n",
    "for I in np.linspace(0,1,20):\n",
    "    #for y_l in np.linspace(1e-5,100,1000):\n",
    "    for dtt in np.linspace(0,0.2,20):\n",
    "        yy_all=I_to_y_SIS(I)\n",
    "        for y_l in yy_all:\n",
    "            miu_pp=miu_p_sis(y_l)\n",
    "            miu_cc=miu_c_sis(y_l)\n",
    "            I_tt=np.abs(miu_cc)/np.abs(miu_pp)\n",
    "            asas+=1\n",
    "            xx.append(I_tt)\n",
    "            yy.append(dtt)\n",
    "            hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "            if y_l<1:\n",
    "                result = types.FrequencySeries(SIS_model(hp_flens.sample_frequencies.data,miu_pp, miu_cc, dtt,y_l),delta_f=N_fs/N_s)\n",
    "            else:\n",
    "                result = types.FrequencySeries([SIS_model(hp_flens.sample_frequencies.data,miu_pp, miu_cc, dtt,12)]*(round(N_s/2)+1),delta_f=N_fs/N_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8b773-e2b6-4d3e-82a4-003867281cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNINGWARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]"
     ]
    }
   ],
   "source": [
    "#固定的参数\n",
    "Z_L=0\n",
    "\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "for SNRRR in [8,12,16]:\n",
    "    for I in np.linspace(0,1,20):\n",
    "        #for y_l in np.linspace(1e-5,100,1000):\n",
    "        for dtt in np.linspace(0,0.2,20):\n",
    "            yy_all=I_to_y_SIS(I)\n",
    "            for y_l in yy_all:\n",
    "                miu_pp=miu_p_sis(y_l)\n",
    "                miu_cc=miu_c_sis(y_l)\n",
    "                asas+=1\n",
    "                xx.append(I_tt)\n",
    "                yy.append(dtt)\n",
    "                hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "                if y_l<1:\n",
    "                    result = types.FrequencySeries(SIS_model(hp_flens.sample_frequencies.data,miu_pp, miu_cc, dtt,y_l),delta_f=N_fs/N_s)\n",
    "                    images=2\n",
    "                else:\n",
    "                    result = types.FrequencySeries([SIS_model(hp_flens.sample_frequencies.data,miu_pp, miu_cc, dtt,12)]*(round(N_s/2)+1),delta_f=N_fs/N_s)\n",
    "                    images=1\n",
    "# 以下PM与SIS完全相同\n",
    "\n",
    "                def get_wave_plus_gaosnoise_t_gen_sis(saaaa):\n",
    "                    hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "                    while True:\n",
    "                        tc=random.uniform(7,8)\n",
    "                        mc_distribution=distributions.MchirpfromUniformMass1Mass2(mc=(5,80))\n",
    "                        q_distribution=distributions.QfromUniformMass1Mass2(q=(0.5,2.0))#0.5-1\n",
    "                        mc_samples = mc_distribution.rvs(size=1)\n",
    "                        q_samples = q_distribution.rvs(size=1)\n",
    "                        mc=mc_samples[0][0]\n",
    "                        q=q_samples[0][0]\n",
    "                        m1,m2=mc_q_to_m1_m2(mc,q)\n",
    "\n",
    "\n",
    "                        zs_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(Z_L,1.0))#MPc\n",
    "                        zs_samples=zs_distribution.rvs(size=1)\n",
    "                        Z_s=zs_samples[0][0]\n",
    "                        D_S=z_to_d_ang(Z_s,70,0.3,0.7)\n",
    "\n",
    "                        distance=d_ang_to_dl(D_S,Z_s)\n",
    "\n",
    "                        sky_distribution = distributions.sky_location.UniformSky()\n",
    "                        sky_samples=sky_distribution.rvs(size=1)\n",
    "                        dec = sky_samples[0][0]#纬度\n",
    "                        ra = sky_samples[0][1]#经度\n",
    "\n",
    "                        psi = random.uniform(0,np.pi*2)#偏振角ψ\n",
    "                        inc=np.arccos(-1.0 + 2.0*np.random.rand())#倾角\n",
    "                        coa_phase=random.uniform(0,np.pi*2)#合并相位\n",
    "                        #IMRPhenomPv2，SEOBNRv4_opt,IMRPhenomTPHM\n",
    "##try 后与PM无本质区别, 除了保存的文件名不同.\n",
    "                        try:\n",
    "                            hp, hc = get_td_waveform(approximant='IMRPhenomTPHM',\n",
    "                                                     mass1=m1*(1+Z_s),#红移质量1\n",
    "                                                     mass2=m2*(1+Z_s),#红移质量2\n",
    "                                                     distance=distance,#距离，MPC\n",
    "                                                     coa_phase=coa_phase,#合并相位\n",
    "                                                     inclination=inc,#轨道和视线的夹角\n",
    "                                                     spin1x=0,\n",
    "                                                     spin1y=0,\n",
    "                                                     spin1z=0,#自旋1\n",
    "                                                     spin2x=0,\n",
    "                                                     spin2y=0,\n",
    "                                                     spin2z=0,#自旋2\n",
    "                                                     eccentricity=0,#轨道偏心率\n",
    "                                                     lambda1=0,#潮汐相，中子星有\n",
    "                                                     lambda2=0,\n",
    "                                                     delta_t=1.0/N_fs,\n",
    "                                                     f_lower=30)\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        fp_1, fc_1 = det_1.antenna_pattern(\n",
    "                                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "                        fp_2, fc_2 = det_2.antenna_pattern(\n",
    "                                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "                        fp_3, fc_3 = det_3.antenna_pattern(\n",
    "                                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "                        fp_4, fc_4 = det_4.antenna_pattern(\n",
    "                                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "\n",
    "                        ht_1 = fp_1*hp + fc_1*hc\n",
    "                        ht_2 = fp_2*hp + fc_2*hc\n",
    "                        ht_3 = fp_3*hp + fc_3*hc\n",
    "                        ht_4 = fp_4*hp + fc_4*hc\n",
    "\n",
    "\n",
    "                        ht_1.resize(N_s)\n",
    "                        ht_1=ht_1.cyclic_time_shift(ht_1.start_time+tc)\n",
    "                        ht_1.start_time=0\n",
    "                        ht_2.resize(N_s)\n",
    "                        ht_2=ht_2.cyclic_time_shift(ht_2.start_time+tc)\n",
    "                        ht_2.start_time=0\n",
    "                        ht_3.resize(N_s)\n",
    "                        ht_3=ht_3.cyclic_time_shift(ht_3.start_time+tc)\n",
    "                        ht_3.start_time=0\n",
    "                        ht_4.resize(N_s)\n",
    "                        ht_4=ht_4.cyclic_time_shift(ht_4.start_time+tc)\n",
    "                        ht_4.start_time=0\n",
    "\n",
    "                        hp_f_1=ht_1.to_frequencyseries()\n",
    "                        hp_flens_1=hp_f_1*result\n",
    "                        hp_t_lens_1=hp_flens_1.to_timeseries()\n",
    "                        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "                        hp_f_2=ht_2.to_frequencyseries()\n",
    "                        hp_flens_2=hp_f_2*result\n",
    "                        hp_t_lens_2=hp_flens_2.to_timeseries()\n",
    "                        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "                        hp_f_3=ht_3.to_frequencyseries()\n",
    "                        hp_flens_3=hp_f_3*result\n",
    "                        hp_t_lens_3=hp_flens_3.to_timeseries()\n",
    "                        #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "                        hp_f_4=ht_4.to_frequencyseries()\n",
    "                        hp_flens_4=hp_f_4*result\n",
    "                        hp_t_lens_4=hp_flens_4.to_timeseries()\n",
    "\n",
    "\n",
    "                        #利用高斯 psd生成噪声：\n",
    "                        noise_et1 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdl)\n",
    "                        #添加非高斯噪声后要用welch方法估计psd——假设没有方法能合理的估计psd（psd中包含各种非高斯的干扰）\n",
    "                        hp_t_lens_plusnoise_1=hp_t_lens_1.copy()\n",
    "                        hp_t_lens_plusnoise_1.data+=noise_et1.data\n",
    "\n",
    "                        noise_et2 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdh)\n",
    "                        hp_t_lens_plusnoise_2=hp_t_lens_2.copy()\n",
    "                        hp_t_lens_plusnoise_2.data+=noise_et2.data\n",
    "\n",
    "                        noise_et3 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdv)\n",
    "                        hp_t_lens_plusnoise_3=hp_t_lens_3.copy()\n",
    "                        hp_t_lens_plusnoise_3.data+=noise_et3.data\n",
    "\n",
    "                        noise_et4 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdk)\n",
    "                        hp_t_lens_plusnoise_4=hp_t_lens_4.copy()\n",
    "                        hp_t_lens_plusnoise_4.data+=noise_et4.data\n",
    "\n",
    "                        snr1 = get_snr(hp_t_lens_1,T_obs,N_fs,psdl_snr.data)\n",
    "                        snr2 = get_snr(hp_t_lens_2,T_obs,N_fs,psdh_snr.data)\n",
    "                        snr3 = get_snr(hp_t_lens_3,T_obs,N_fs,psdv_snr.data)\n",
    "                        snr4 = get_snr(hp_t_lens_4,T_obs,N_fs,psdk_snr.data)\n",
    "                        snr=(snr1**2+snr2**2+snr3**2+snr4**2)**0.5\n",
    "                        #print(snr)\n",
    "\n",
    "                        #print(snr,D_S,D_LS,D_L,distance)\n",
    "                        if snr<(SNRRR-2) or snr>(SNRRR+2):\n",
    "                            continue\n",
    "\n",
    "                        L11data = (hp_t_lens_plusnoise_1.to_frequencyseries() / psdl_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "                        H11data = (hp_t_lens_plusnoise_2.to_frequencyseries() / psdh_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "                        V11data = (hp_t_lens_plusnoise_3.to_frequencyseries() / psdv_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "                        K11data = (hp_t_lens_plusnoise_4.to_frequencyseries() / psdk_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "\n",
    "                        canshu=[dtt,I_tt]#12个\n",
    "\n",
    "                        return [L11data.data,H11data.data,V11data.data,K11data.data],[1.0],[snr,m1+m2],canshu\n",
    "\n",
    "\n",
    "                def get_wave_plus_gaosnoise_t_gen_cai_sis(data):\n",
    "                    nnnyyu=2**5\n",
    "                    samples_all=torch.zeros((data.shape[0],2,nnnyyu))\n",
    "                    for i in range(data.shape[0]):\n",
    "                        estimator.eval()\n",
    "                        with torch.no_grad():\n",
    "                            samples = estimator.flow(data[i].reshape(1,4,40960).cuda()).sample((nnnyyu,)).cpu()\n",
    "                            samples = postprocess(samples)\n",
    "\n",
    "                        samples_all[i,0,:]=samples[:,0,0]\n",
    "                        samples_all[i,1,:]=samples[:,0,1]\n",
    "                    return samples_all\n",
    "\n",
    "\n",
    "                pool = Pool(processes=56)\n",
    "                results = pool.map(get_wave_plus_gaosnoise_t_gen_sis, [0.5]*100)\n",
    "                all_x_vail_data = torch.tensor(np.concatenate([x for x,y,z,u in results]).reshape(100,4,40960),dtype=torch.float32)\n",
    "                #all_x_vail=get_wave_plus_gaosnoise_t_gen_cai_sis(all_x_vail_data).reshape(100,2,2**5)\n",
    "                all_y_vail = torch.tensor(np.concatenate([y for x,y,z,u in results]).reshape(100,1),dtype=torch.float32)\n",
    "                all_z_vail = torch.tensor(np.concatenate([z for x,y,z,u in results]).reshape(100,2),dtype=torch.float32)\n",
    "                all_u_vail = torch.tensor(np.concatenate([u for x,y,z,u in results]).reshape(100,2),dtype=torch.float32)\n",
    "                pool.close()\n",
    "                pool.join()\n",
    "\n",
    "                np.save(f'./data/I_dt/new/test_SIS_{images}_data_{I}_{dtt}_{SNRRR}.npy',all_x_vail_data)\n",
    "                np.save(f'./data/I_dt/new/test_SIS_{images}_label_{I}_{dtt}_{SNRRR}.npy',all_y_vail)\n",
    "                np.save(f'./data/I_dt/new/test_SIS_{images}_err_{I}_{dtt}_{SNRRR}.npy',all_z_vail)\n",
    "                np.save(f'./data/I_dt/new/test_SIS_{images}_canshu_{I}_{dtt}_{SNRRR}.npy',all_u_vail)\n",
    "\n",
    "                #np.save(f'./data/I_dt/tes_SISt_data_roc_sis_{M_L}_{y_l}_{SNRRR}.npy',all_x_vail)\n",
    "                \n",
    "                \n",
    "                #np.save(f'./data/I_dt/test_PM_data_{I}_{dtt}_{SNRRR}.npy',all_x_vail_data)\n",
    "                ##np.save(f'./data/I_dt/test_PM_data__{I}_{y_l}_{SNRRR}.npy',all_x_vail)\n",
    "                #np.save(f'./data/I_dt/test_PM_label_{I}_{dtt}_{SNRRR}.npy',all_y_vail)\n",
    "                #np.save(f'./data/I_dt/test_PM_err_{I}_{dtt}_{SNRRR}.npy',all_z_vail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04b559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9196d82-05c7-4440-b857-42f693eed15b",
   "metadata": {},
   "source": [
    "# 参数精度数据集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f0816a9-2b29-455d-aaa2-7209e36061ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#1024——glitch生成\n",
    "import matplotlib.pyplot as pp\n",
    "import matplotlib.pyplot as plt\n",
    "from pycbc.waveform import get_td_waveform,get_fd_waveform\n",
    "from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "from pycbc.filter import sigma\n",
    "from pycbc import types\n",
    "from pycbc.detector import Detector\n",
    "from pycbc.filter import matched_filter\n",
    "import pycbc\n",
    "from pycbc.psd import welch\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "from pycbc import waveform\n",
    "import scipy\n",
    "import h5py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from pycbc import distributions\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from gwpy.timeseries import TimeSeries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_psd='./'\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "#函数定义\n",
    "def z_to_d_ang(z, H0, Omega_m, Omega_Lambda):#输入红移输出直径距离\n",
    "    c = 299792.458  # 光速，单位：km/s\n",
    "    # 定义被积函数\n",
    "    integrand = lambda z: 1 / np.sqrt(Omega_m * (1 + z)**3 + Omega_Lambda)\n",
    "    # 积分计算\n",
    "    result, _ = quad(integrand, 0, z)\n",
    "    # 计算距离\n",
    "    distance = c / (H0 * (1+z) )* result\n",
    "    return distance\n",
    "\n",
    "\n",
    "def zl_zs_to_dsl_ang(zl,zs, H0, Omega_m, Omega_Lambda):#输入红移、输出直径距离\n",
    "    c = 299792.458  # 光速，单位：km/s\n",
    "    integrand = lambda z: 1 / np.sqrt(Omega_m * (1 + z)**3 + Omega_Lambda)\n",
    "    result, _ = quad(integrand, zl, zs)\n",
    "    distance = c / (H0 * (1+zs) )* result\n",
    "    return distance\n",
    "\n",
    "\n",
    "def d_ang_to_dl(D_ang,z):#输入角直径距离、输出光度距离\n",
    "    return D_ang*(1+z)**2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#点质量透镜模型\n",
    "class Point_mass_lens_model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def F_f(self, f, M_LZ, epsilon, D_L, xi_0, D_s):\n",
    "        return np.abs(self.miu_p(self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))**0.5 - \\\n",
    "            1j * np.abs(self.miu_c(self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))**0.5 * \\\n",
    "            np.exp(2j * np.pi * f * self.dt(M_LZ, self.y(epsilon, D_L, xi_0, D_s), self.beta(self.y(epsilon, D_L, xi_0, D_s))))\n",
    "    \n",
    "    def miu_p(self, y, beta):\n",
    "        return 0.5 + (y**2 + 2) / (2 * y * beta)\n",
    "    \n",
    "    def miu_c(self, y, beta):\n",
    "        return 0.5 - (y**2 + 2) / (2 * y * beta)\n",
    "    #G:m³/kg·s²\n",
    "    def dt(self, M_LZ, y, beta):#单位s\n",
    "        return 4 * M_LZ*(y * beta / 2 + np.log((beta + y) / (beta - y))) * scipy.constants.G / scipy.constants.c**3 *(1.989e30)\n",
    "    \n",
    "    def beta(self, y):\n",
    "        return (y**2 + 4)**0.5\n",
    "    \n",
    "    def y(self, epsilon, D_L, xi_0, D_s):\n",
    "        return epsilon * D_L / xi_0 / D_s\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def yy_ll(epsilon, D_L, xi_0, D_s):\n",
    "    return epsilon * D_L / xi_0 / D_s\n",
    "    \n",
    "def miu_p_sis(y_l):\n",
    "    return 1+1/y_l\n",
    "\n",
    "def miu_c_sis(y_l):\n",
    "    return -1+1/y_l\n",
    "    \n",
    "def det_t_sis(M_L,y_l,zl):\n",
    "    return 8*M_L*(1+zl)*y_l* scipy.constants.G / scipy.constants.c**3 *(1.989e30)\n",
    "    \n",
    "    \n",
    "def miu_p_pm(y_l):\n",
    "    return 1/2+(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
    "\n",
    "def miu_c_pm(y_l):\n",
    "    return 1/2-(y_l**2+2)/(2*y_l*(y_l**2+4)**0.5)\n",
    "    \n",
    "def det_t_pm(M_L,y_l,zl):\n",
    "    return 2*M_L*(1+zl)*(y_l*(y_l**2+4)**0.5+2*np.log(((y_l**2+4)**0.5+y_l)/((y_l**2+4)**0.5-y_l)))* scipy.constants.G / scipy.constants.c**3 *(1.989e30)\n",
    "    \n",
    "    \n",
    "def PM_model(f, miu_p, miu_c, det_t):\n",
    "    return np.abs(miu_p)**0.5 - 1j * np.abs(miu_c)**0.5 *  np.exp(2j * np.pi * f * det_t)\n",
    "\n",
    "def SIS_model(f, miu_p, miu_c, det_t,y_l):\n",
    "    if y_l<1:\n",
    "        return np.abs(miu_p)**0.5 - 1j * np.abs(miu_c)**0.5 *  np.exp(2j * np.pi * f * det_t)\n",
    "    else:\n",
    "        return np.abs(miu_p)**0.5 \n",
    "    \n",
    "def y_lens(epsilon, D_L, xi_0, D_s):\n",
    "    return epsilon * D_L / xi_0 / D_s\n",
    "    \n",
    "def M_L_Z(M_L,z):\n",
    "    return M_L*(1+z)\n",
    "    \n",
    "def x_i_0(M_L,D_LS,D_L,D_S): #G:m³/kg·s² #m^1 kg^-1 Mc^1  Mpc^1 单位转化成MPc,,,,1.989×1030 千克,,,3.0857E+22\n",
    "    return ((4*scipy.constants.G*M_L/scipy.constants.c**2)*(D_LS*D_L/D_S) /(3.0857e22)*(1.989e30))**0.5\n",
    "\n",
    "def mc_q_to_m1_m2(mc,q):\n",
    "    m1=(mc**5*(1+q)/q**3)**(1/5)\n",
    "    m2=m1*q\n",
    "    return m1,m2\n",
    "\n",
    "\n",
    "def get_snr(data,T_obs,fs,psd):\n",
    "    #波形、1、频率、psd\n",
    "    N = T_obs*fs\n",
    "    delta_f = 1.0/T_obs\n",
    "    delta_t = 1.0/fs\n",
    "\n",
    "#     win = tukey(N,alpha=1.0/8.0)\n",
    "    idx = np.argwhere(psd==0.0)\n",
    "    psd[idx] = 1e300    \n",
    "\n",
    "    xf = np.fft.rfft(data)*delta_t\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(np.real(xf))\n",
    "    #plt.plot(np.imag(xf))\n",
    "    SNRsq = 4.0*np.sum((np.abs(xf)**2)/psd)*delta_f\n",
    "    return np.sqrt(SNRsq)\n",
    "\n",
    "@np.vectorize\n",
    "def gw_waveform(f,A,D,m1,m2,t_c,psi_c,z):\n",
    "    M=m1+m2\n",
    "    qq=m1*m2/M**2\n",
    "    Mz=(1+z)*M\n",
    "    Mc=qq**(3/5)*Mz\n",
    "    f_cut=1/(6**(3/2)*np.pi*Mz) / scipy.constants.G * scipy.constants.c**3 /(1.989e30)\n",
    "    def fi(f,t_c,psi_c,qq,Mc):\n",
    "        return 2*np.pi*f*t_c-psi_c-np.pi/4+3/4*(8*np.pi*Mc*f)**(-5/3)*(1+20/9*(743/336+11/4*qq)*(np.pi*Mz*f)**(2/3)-16*np.pi*(np.pi*Mz*f))\n",
    "    if f_cut<f:\n",
    "        return 0\n",
    "    else:\n",
    "        return A/D*Mc**(5/6)*f**(-7/6)*np.exp(1j*fi(f,t_c,psi_c,qq,Mc))*1e-19/0.27\n",
    "\n",
    "\n",
    "#固定的参数\n",
    "calculator = Point_mass_lens_model()\n",
    "T_obs=10\n",
    "N_fs=4096#采样率为4096Hz\n",
    "N_s=T_obs*N_fs#对应时域为10s\n",
    "\n",
    "flen = round(N_s/2)+1\n",
    "delta_f = 1.0 / T_obs\n",
    "delta_t=1/N_fs\n",
    "f_low=30\n",
    "flow=30\n",
    "\n",
    "tsamples = int(T_obs / delta_t)\n",
    "\n",
    "# 打开txt文件以读取内容\n",
    "with open(data_psd+'/aligo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdh = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdh.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdh.sample_frequencies<f_low]=0\n",
    "psdh.data=y_new\n",
    "psdh_snr = psdh.copy()\n",
    "\n",
    "# 打开txt文件以读取内容\n",
    "with open(data_psd+'/aligo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdl = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdl.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdl.sample_frequencies<f_low]=0\n",
    "psdl.data=y_new\n",
    "psdl_snr = psdl.copy()\n",
    "\n",
    "# 打开txt文件以读取内容\n",
    "with open(data_psd+'/avirgo_O4high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdv = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdv.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdv.sample_frequencies<f_low]=0\n",
    "psdv.data=y_new\n",
    "psdv_snr = psdv.copy()\n",
    "\n",
    "# 打开txt文件以读取内容\n",
    "with open(data_psd+'/k1_o4_high.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# 解析数据\n",
    "data_lines = [line.strip().split() for line in lines]\n",
    "\n",
    "data = [[float(value) for value in line] for line in data_lines]\n",
    "\n",
    "list_los = []  # 用于存储第一列数据\n",
    "list_losvail = []  # 用于存储第二列数据\n",
    "# 遍历数据并将其添加到相应的列表中\n",
    "for row in data:\n",
    "    list_los.append(row[0])  # 将第一列数据添加到list_los\n",
    "    list_losvail.append(row[1]**2)  # 将第二列数据添加到list_losvail\n",
    "    \n",
    "    \n",
    "psdk = pycbc.psd.aLIGO140MpcT1800545(flen, delta_f, flow)\n",
    "interp_function = interp1d(list_los, list_losvail, kind='linear')\n",
    "y_new = interp_function(psdk.sample_frequencies)  # 生成的 y 值\n",
    "y_new[psdk.sample_frequencies<f_low]=0\n",
    "psdk.data=y_new\n",
    "psdk_snr = psdk.copy()\n",
    "\n",
    "\n",
    "#! 后面开始与前面不同\n",
    "\n",
    "#固定的参数\n",
    "calculator = Point_mass_lens_model()\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import h5py\n",
    "\n",
    "\n",
    "for SSRRNN in [8,16,24,32]:\n",
    "    def get_wave_plus_gaosnoise_t_gen(saaaa):\n",
    "        hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "        while True:\n",
    "            epsilon=random.uniform(1e-6,0.5)*1e-6#MPc\n",
    "\n",
    "            #dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(10,6000))#MPc\n",
    "            #dl_samples=dl_distribution.rvs(size=1)\n",
    "            #D_L=dl_samples[0][0]\n",
    "            #dl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(D_L,6000+D_L))#MPc\n",
    "            #dl_samples=dl_distribution.rvs(size=1)\n",
    "            #D_LS=dl_samples[0][0]-D_L#MPc\n",
    "\n",
    "            M_L=random.uniform(1e3,1e5)#M\n",
    "\n",
    "\n",
    "            zl_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(0,1.0))#MPc\n",
    "            zl_samples=zl_distribution.rvs(size=1)\n",
    "            Z_L=zl_samples[0][0]\n",
    "\n",
    "            zs_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(Z_L,1.0))#MPc\n",
    "            zs_samples=zs_distribution.rvs(size=1)\n",
    "            Z_s=zs_samples[0][0]\n",
    "\n",
    "            D_S=z_to_d_ang(Z_s,70,0.3,0.7)\n",
    "            D_LS=zl_zs_to_dsl_ang(Z_L,Z_s,70,0.3,0.7)\n",
    "            D_L=z_to_d_ang(Z_L,70,0.3,0.7)\n",
    "\n",
    "            #z_to_DL\n",
    "            M_LZ=M_L_Z(M_L,Z_L)#M\n",
    "            xi_0=x_i_0(M_L,D_LS,D_L,D_S)\n",
    "            y_l=yy_ll(epsilon, D_L, xi_0, D_S)\n",
    "\n",
    "            #print(calculator.dt(M_LZ, calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "            #print(calculator.miu_p(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "            #print(calculator.miu_c(calculator.y(epsilon, D_L, xi_0, D_S), calculator.beta(calculator.y(epsilon, D_L, xi_0, D_S))))\n",
    "\n",
    "            dtt=det_t_pm(M_L,y_l,Z_L)\n",
    "            miu_pp=miu_p_pm(y_l)\n",
    "            miu_cc=miu_c_pm(y_l)\n",
    "\n",
    "            I_tt=np.abs(miu_cc)/np.abs(miu_pp)\n",
    "            #if dtt<2.25e-3 or dtt>3.52 or miu_pp<1.7 or miu_pp>10.51 or miu_cc<-9.51 or miu_cc>-0.17:\n",
    "            #    continue\n",
    "            if dtt>0.2 or I_tt<0 or I_tt>1:\n",
    "                continue\n",
    "            #print(dtt)\n",
    "            #print(dtt,miu_pp,miu_cc)\n",
    "            result = types.FrequencySeries(PM_model(hp_flens.sample_frequencies.data,miu_pp, miu_cc, dtt),delta_f=N_fs/N_s)\n",
    "\n",
    "\n",
    "\n",
    "            tc=random.uniform(7,8)\n",
    "            mc_distribution=distributions.MchirpfromUniformMass1Mass2(mc=(5,80))\n",
    "            q_distribution=distributions.QfromUniformMass1Mass2(q=(0.5,2.0))#0.5-1\n",
    "            mc_samples = mc_distribution.rvs(size=1)\n",
    "            q_samples = q_distribution.rvs(size=1)\n",
    "            mc=mc_samples[0][0]\n",
    "            q=q_samples[0][0]\n",
    "            m1,m2=mc_q_to_m1_m2(mc,q)\n",
    "\n",
    "            distance=d_ang_to_dl(D_S,Z_s)\n",
    "\n",
    "            sky_distribution = distributions.sky_location.UniformSky()\n",
    "            sky_samples=sky_distribution.rvs(size=1)\n",
    "            dec = sky_samples[0][0]#纬度\n",
    "            ra = sky_samples[0][1]#经度\n",
    "\n",
    "            psi = random.uniform(0,np.pi*2)#偏振角ψ\n",
    "            inc=np.arccos(-1.0 + 2.0*np.random.rand())#倾角\n",
    "            coa_phase=random.uniform(0,np.pi*2)#合并相位\n",
    "            #IMRPhenomPv2，SEOBNRv4_opt,IMRPhenomTPHM\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                hp, hc = get_td_waveform(approximant='IMRPhenomTPHM',\n",
    "                                         mass1=m1*(1+Z_s),#红移质量1\n",
    "                                         mass2=m2*(1+Z_s),#红移质量2\n",
    "                                         distance=distance,#距离，MPC\n",
    "                                         coa_phase=coa_phase,#合并相位\n",
    "                                         inclination=inc,#轨道和视线的夹角\n",
    "                                         spin1x=0,\n",
    "                                         spin1y=0,\n",
    "                                         spin1z=0,#自旋1\n",
    "                                         spin2x=0,\n",
    "                                         spin2y=0,\n",
    "                                         spin2z=0,#自旋2\n",
    "                                         eccentricity=0,#轨道偏心率\n",
    "                                         lambda1=0,#潮汐相，中子星有\n",
    "                                         lambda2=0,\n",
    "                                         delta_t=1.0/N_fs,\n",
    "                                         f_lower=30)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            fp_1, fc_1 = det_1.antenna_pattern(\n",
    "                            right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "            fp_2, fc_2 = det_2.antenna_pattern(\n",
    "                            right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "            fp_3, fc_3 = det_3.antenna_pattern(\n",
    "                            right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "            fp_4, fc_4 = det_4.antenna_pattern(\n",
    "                            right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "\n",
    "            ht_1 = fp_1*hp + fc_1*hc\n",
    "            ht_2 = fp_2*hp + fc_2*hc\n",
    "            ht_3 = fp_3*hp + fc_3*hc\n",
    "            ht_4 = fp_4*hp + fc_4*hc\n",
    "\n",
    "\n",
    "            ht_1.resize(N_s)\n",
    "            ht_1=ht_1.cyclic_time_shift(ht_1.start_time+tc)\n",
    "            ht_1.start_time=0\n",
    "            ht_2.resize(N_s)\n",
    "            ht_2=ht_2.cyclic_time_shift(ht_2.start_time+tc)\n",
    "            ht_2.start_time=0\n",
    "            ht_3.resize(N_s)\n",
    "            ht_3=ht_3.cyclic_time_shift(ht_3.start_time+tc)\n",
    "            ht_3.start_time=0\n",
    "            ht_4.resize(N_s)\n",
    "            ht_4=ht_4.cyclic_time_shift(ht_4.start_time+tc)\n",
    "            ht_4.start_time=0\n",
    "\n",
    "            hp_f_1=ht_1.to_frequencyseries()\n",
    "            hp_flens_1=hp_f_1*result\n",
    "            hp_t_lens_1=hp_flens_1.to_timeseries()\n",
    "            #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "            hp_f_2=ht_2.to_frequencyseries()\n",
    "            hp_flens_2=hp_f_2*result\n",
    "            hp_t_lens_2=hp_flens_2.to_timeseries()\n",
    "            #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "            hp_f_3=ht_3.to_frequencyseries()\n",
    "            hp_flens_3=hp_f_3*result\n",
    "            hp_t_lens_3=hp_flens_3.to_timeseries()\n",
    "            #snr1 = get_snr(hp,T_obs,N_fs,psdl_snr.data)\n",
    "            hp_f_4=ht_4.to_frequencyseries()\n",
    "            hp_flens_4=hp_f_4*result\n",
    "            hp_t_lens_4=hp_flens_4.to_timeseries()\n",
    "\n",
    "\n",
    "            #利用高斯 psd生成噪声：\n",
    "            noise_et1 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdl)\n",
    "            #添加非高斯噪声后要用welch方法估计psd——假设没有方法能合理的估计psd（psd中包含各种非高斯的干扰）\n",
    "            hp_t_lens_plusnoise_1=hp_t_lens_1.copy()\n",
    "            hp_t_lens_plusnoise_1.data+=noise_et1.data\n",
    "\n",
    "            noise_et2 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdh)\n",
    "            hp_t_lens_plusnoise_2=hp_t_lens_2.copy()\n",
    "            hp_t_lens_plusnoise_2.data+=noise_et2.data\n",
    "\n",
    "            noise_et3 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdv)\n",
    "            hp_t_lens_plusnoise_3=hp_t_lens_3.copy()\n",
    "            hp_t_lens_plusnoise_3.data+=noise_et3.data\n",
    "\n",
    "            noise_et4 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdk)\n",
    "            hp_t_lens_plusnoise_4=hp_t_lens_4.copy()\n",
    "            hp_t_lens_plusnoise_4.data+=noise_et4.data\n",
    "\n",
    "            snr1 = get_snr(hp_t_lens_1,T_obs,N_fs,psdl_snr.data)\n",
    "            snr2 = get_snr(hp_t_lens_2,T_obs,N_fs,psdh_snr.data)\n",
    "            snr3 = get_snr(hp_t_lens_3,T_obs,N_fs,psdv_snr.data)\n",
    "            snr4 = get_snr(hp_t_lens_4,T_obs,N_fs,psdk_snr.data)\n",
    "            snr=(snr1**2+snr2**2+snr3**2+snr4**2)**0.5\n",
    "            #print(snr)\n",
    "            #print(snr,SSRRNN)\n",
    "            #print(snr,D_S,D_LS,D_L,distance)\n",
    "            if snr<(SSRRNN-2) or snr>(SSRRNN+2):\n",
    "                continue\n",
    "\n",
    "\n",
    "            L11data = (hp_t_lens_plusnoise_1.to_frequencyseries() / psdl_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "            H11data = (hp_t_lens_plusnoise_2.to_frequencyseries() / psdh_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "            V11data = (hp_t_lens_plusnoise_3.to_frequencyseries() / psdv_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "            K11data = (hp_t_lens_plusnoise_4.to_frequencyseries() / psdk_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "\n",
    "            canshu=[dtt,I_tt]#12个\n",
    "\n",
    "            return [[L11data.data,H11data.data,V11data.data,K11data.data]],[canshu]\n",
    "    \n",
    "    num=200#总数\n",
    "    pool = Pool(processes=56)\n",
    "    results = pool.map(get_wave_plus_gaosnoise_t_gen, [0.5]*num)\n",
    "    all_x = np.concatenate([x for x,y in results])\n",
    "    all_y = np.concatenate([y for x,y in results])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    filename = f'./data/PM_theta_{SSRRNN}.h5'\n",
    "    h5f = h5py.File(filename, 'w')\n",
    "    h5f.create_dataset('theta',dtype=np.float32, data=all_y)\n",
    "    h5f.create_dataset('x',dtype=np.float32,data=all_x)\n",
    "    h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e803570-0591-436d-9ce9-dbbd6529c42b",
   "metadata": {},
   "source": [
    "# 这之后的好像没用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2625242a-6a8b-4538-a729-7de443662737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wave_plus_gaosnoise_t_nolens(saaaa):\n",
    "    hp_flens=types.FrequencySeries(np.zeros(round(N_s/2)+1),delta_f=1.0 / T_obs)#采样定律\n",
    "    while True:\n",
    "        tc=random.uniform(7,8)\n",
    "        mc_distribution=distributions.MchirpfromUniformMass1Mass2(mc=(5,80))\n",
    "        q_distribution=distributions.QfromUniformMass1Mass2(q=(0.5,2.0))#0.5-1\n",
    "        mc_samples = mc_distribution.rvs(size=1)\n",
    "        q_samples = q_distribution.rvs(size=1)\n",
    "        mc=mc_samples[0][0]\n",
    "        q=q_samples[0][0]\n",
    "        m1,m2=mc_q_to_m1_m2(mc,q)\n",
    "\n",
    "        \n",
    "        zs_distribution=distributions.power_law.UniformPowerLaw(dim=3,bound =(Z_L,1.0))#MPc\n",
    "        zs_samples=zs_distribution.rvs(size=1)\n",
    "        Z_s=zs_samples[0][0]\n",
    "        D_S=z_to_d_ang(Z_s,70,0.3,0.7)\n",
    "        \n",
    "        distance=d_ang_to_dl(D_S,Z_s)\n",
    "\n",
    "        sky_distribution = distributions.sky_location.UniformSky()\n",
    "        sky_samples=sky_distribution.rvs(size=1)\n",
    "        dec = sky_samples[0][0]#纬度\n",
    "        ra = sky_samples[0][1]#经度\n",
    "\n",
    "        psi = random.uniform(0,np.pi*2)#偏振角ψ\n",
    "        inc=np.arccos(-1.0 + 2.0*np.random.rand())#倾角\n",
    "        coa_phase=random.uniform(0,np.pi*2)#合并相位\n",
    "        #IMRPhenomPv2，SEOBNRv4_opt,IMRPhenomTPHM\n",
    "\n",
    "        try:\n",
    "            hp, hc = get_td_waveform(approximant='IMRPhenomTPHM',\n",
    "                                     mass1=m1*(1+Z_s),#红移质量1\n",
    "                                     mass2=m2*(1+Z_s),#红移质量2\n",
    "                                     distance=distance,#距离，MPC\n",
    "                                     coa_phase=coa_phase,#合并相位\n",
    "                                     inclination=inc,#轨道和视线的夹角\n",
    "                                     spin1x=0,\n",
    "                                     spin1y=0,\n",
    "                                     spin1z=0,#自旋1\n",
    "                                     spin2x=0,\n",
    "                                     spin2y=0,\n",
    "                                     spin2z=0,#自旋2\n",
    "                                     eccentricity=0,#轨道偏心率\n",
    "                                     lambda1=0,#潮汐相，中子星有\n",
    "                                     lambda2=0,\n",
    "                                     delta_t=1.0/N_fs,\n",
    "                                     f_lower=30)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        fp_1, fc_1 = det_1.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_2, fc_2 = det_2.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_3, fc_3 = det_3.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "        fp_4, fc_4 = det_4.antenna_pattern(\n",
    "                        right_ascension=ra, declination=dec, polarization=psi, t_gps=tc)\n",
    "\n",
    "        ht_1 = fp_1*hp + fc_1*hc\n",
    "        ht_2 = fp_2*hp + fc_2*hc\n",
    "        ht_3 = fp_3*hp + fc_3*hc\n",
    "        ht_4 = fp_4*hp + fc_4*hc\n",
    "\n",
    "\n",
    "        ht_1.resize(N_s)\n",
    "        ht_1=ht_1.cyclic_time_shift(ht_1.start_time+tc)\n",
    "        ht_1.start_time=0\n",
    "        ht_2.resize(N_s)\n",
    "        ht_2=ht_2.cyclic_time_shift(ht_2.start_time+tc)\n",
    "        ht_2.start_time=0\n",
    "        ht_3.resize(N_s)\n",
    "        ht_3=ht_3.cyclic_time_shift(ht_3.start_time+tc)\n",
    "        ht_3.start_time=0\n",
    "        ht_4.resize(N_s)\n",
    "        ht_4=ht_4.cyclic_time_shift(ht_4.start_time+tc)\n",
    "        ht_4.start_time=0\n",
    "\n",
    "        #无透镜的\n",
    "        hp_t_lens_1=ht_1.copy()\n",
    "        hp_t_lens_2=ht_2.copy()\n",
    "        hp_t_lens_3=ht_3.copy()\n",
    "        hp_t_lens_4=ht_4.copy()\n",
    "\n",
    "\n",
    "        #利用高斯 psd生成噪声：\n",
    "        noise_et1 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdl)\n",
    "        #添加非高斯噪声后要用welch方法估计psd——假设没有方法能合理的估计psd（psd中包含各种非高斯的干扰）\n",
    "        hp_t_lens_plusnoise_1=hp_t_lens_1.copy()\n",
    "        hp_t_lens_plusnoise_1.data+=noise_et1.data\n",
    "\n",
    "        noise_et2 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdh)\n",
    "        hp_t_lens_plusnoise_2=hp_t_lens_2.copy()\n",
    "        hp_t_lens_plusnoise_2.data+=noise_et2.data\n",
    "\n",
    "        noise_et3 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdv)\n",
    "        hp_t_lens_plusnoise_3=hp_t_lens_3.copy()\n",
    "        hp_t_lens_plusnoise_3.data+=noise_et3.data\n",
    "\n",
    "        noise_et4 = pycbc.noise.noise_from_psd(tsamples, delta_t, psdk)\n",
    "        hp_t_lens_plusnoise_4=hp_t_lens_4.copy()\n",
    "        hp_t_lens_plusnoise_4.data+=noise_et4.data\n",
    "\n",
    "        snr1 = get_snr(hp_t_lens_1,T_obs,N_fs,psdl_snr.data)\n",
    "        snr2 = get_snr(hp_t_lens_2,T_obs,N_fs,psdh_snr.data)\n",
    "        snr3 = get_snr(hp_t_lens_3,T_obs,N_fs,psdv_snr.data)\n",
    "        snr4 = get_snr(hp_t_lens_4,T_obs,N_fs,psdk_snr.data)\n",
    "        snr=(snr1**2+snr2**2+snr3**2+snr4**2)**0.5\n",
    "        #print(snr)\n",
    "\n",
    "        #print(snr,D_S,D_LS,D_L,distance)\n",
    "        if snr<(SNRRR-2) or snr>(SNRRR+2):\n",
    "            continue\n",
    "\n",
    "        L11data = (hp_t_lens_plusnoise_1.to_frequencyseries() / psdl_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        H11data = (hp_t_lens_plusnoise_2.to_frequencyseries() / psdh_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        V11data = (hp_t_lens_plusnoise_3.to_frequencyseries() / psdv_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "        K11data = (hp_t_lens_plusnoise_4.to_frequencyseries() / psdk_snr**0.5).to_timeseries()#要除以0置成正无穷的\n",
    "\n",
    "        return [L11data.data,H11data.data,V11data.data,K11data.data],[0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a090f-7656-46d9-ab5b-11ddb86cdefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27fbd9-34f3-443f-a8b8-c672127aa993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82474992-80e4-4c37-9c5d-982440aca68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e9ef3-2e6f-40e7-b5fa-7211658e0130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING\n",
      "WARNINGWARNINGWARNINGWARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      "\n",
      "\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      "WARNINGWARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING\n",
      "WARNINGWARNINGWARNINGWARNINGWARNINGWARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING\n",
      "\n",
      "WARNING\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNINGWARNINGWARNING\n",
      "\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING\n",
      "\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNINGWARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]WARNING\n",
      ": IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n"
     ]
    }
   ],
   "source": [
    "#固定的参数\n",
    "Z_L=0\n",
    "\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "\n",
    "\n",
    "for SNRRR in [16,24,32]:\n",
    "    for iii in range(4):\n",
    "        pool = Pool(processes=56)\n",
    "        results = pool.map(get_wave_plus_gaosnoise_t_nolens, [0.5]*10000)\n",
    "        all_x_vail_data = torch.tensor(np.concatenate([x for x,y in results]).reshape(10000,4,40960),dtype=torch.float32)\n",
    "        #all_x_vail=get_wave_plus_gaosnoise_t_gen_cai_sis(all_x_vail_data).reshape(100,2,2**5)\n",
    "        all_y_vail = torch.tensor(np.concatenate([y for x,y in results]).reshape(10000,1),dtype=torch.float32)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        np.save(f'./data/I_dt/test_nolens_data_{SNRRR}_{iii}.npy',all_x_vail_data)\n",
    "        #np.save(f'./data/I_dt/tes_SISt_data_roc_sis_{M_L}_{y_l}_{SNRRR}.npy',all_x_vail)\n",
    "        np.save(f'./data/I_dt/test_nolens_label_{SNRRR}_{iii}.npy',all_y_vail)\n",
    "\n",
    "\n",
    "        #np.save(f'./data/I_dt/test_PM_data_{I}_{dtt}_{SNRRR}.npy',all_x_vail_data)\n",
    "        ##np.save(f'./data/I_dt/test_PM_data__{I}_{y_l}_{SNRRR}.npy',all_x_vail)\n",
    "        #np.save(f'./data/I_dt/test_PM_label_{I}_{dtt}_{SNRRR}.npy',all_y_vail)\n",
    "        #np.save(f'./data/I_dt/test_PM_err_{I}_{dtt}_{SNRRR}.npy',all_z_vail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe7969-d5d4-42cd-8b68-6549df085a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "$$$$$$$$$$$$$$$$$$$$$$$￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥￥\n",
    "\n",
    "#固定的参数\n",
    "Z_L=0\n",
    "\n",
    "det_1 = Detector('L1')\n",
    "det_2 = Detector('H1')\n",
    "det_3 = Detector('V1')\n",
    "det_4 = Detector('K1')\n",
    "\n",
    "\n",
    "for SNRRR in [8]:\n",
    "    for iii in range(4):\n",
    "        pool = Pool(processes=56)\n",
    "        results = pool.map(get_wave_plus_gaosnoise_t_nolens, [0.5]*10000)\n",
    "        all_x_vail_data = torch.tensor(np.concatenate([x for x,y in results]).reshape(10000,4,40960),dtype=torch.float32)\n",
    "        #all_x_vail=get_wave_plus_gaosnoise_t_gen_cai_sis(all_x_vail_data).reshape(100,2,2**5)\n",
    "        all_y_vail = torch.tensor(np.concatenate([y for x,y in results]).reshape(10000,1),dtype=torch.float32)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        np.save(f'./data/I_dt/test_nolens_data_{SNRRR}_{iii}.npy',all_x_vail_data)\n",
    "        #np.save(f'./data/I_dt/tes_SISt_data_roc_sis_{M_L}_{y_l}_{SNRRR}.npy',all_x_vail)\n",
    "        np.save(f'./data/I_dt/test_nolens_label_{SNRRR}_{iii}.npy',all_y_vail)\n",
    "\n",
    "\n",
    "        #np.save(f'./data/I_dt/test_PM_data_{I}_{dtt}_{SNRRR}.npy',all_x_vail_data)\n",
    "        ##np.save(f'./data/I_dt/test_PM_data__{I}_{y_l}_{SNRRR}.npy',all_x_vail)\n",
    "        #np.save(f'./data/I_dt/test_PM_label_{I}_{dtt}_{SNRRR}.npy',all_y_vail)\n",
    "        #np.save(f'./data/I_dt/test_PM_err_{I}_{dtt}_{SNRRR}.npy',all_z_vail)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
